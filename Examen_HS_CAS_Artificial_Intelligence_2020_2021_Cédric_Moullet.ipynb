{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Examen - HS CAS Artificial Intelligence 2020-2021 Cédric Moullet",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buche2/CAS_AI_2020_2021/blob/main/Examen_HS_CAS_Artificial_Intelligence_2020_2021_C%C3%A9dric_Moullet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP5wbQPXLQGc",
        "cellView": "form"
      },
      "source": [
        "Bearbeitungs-Zeit = '10:00 - 12:00' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsJ-FKO8KtqH",
        "cellView": "form"
      },
      "source": [
        "@title Date fields\n",
        "Datum = '2021-04-06' #@param {type:\"date\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsbmY_ZwK3qA",
        "cellView": "form"
      },
      "source": [
        "Name = 'Moullet' #@param {type:\"string\"}\n",
        "Vorname = 'C\\xE9dric' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7gRpQLXQSID"
      },
      "source": [
        "# **Deeplearning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE8XB_pKC2kS"
      },
      "source": [
        "##**1 Gradient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQWFdmaYDkEv"
      },
      "source": [
        "### Aufgabe 1:\n",
        "\n",
        "Für eine mehrdimensionale Funktion $\\displaystyle f\\colon \\mathbf {R} ^{n}\\to \\mathbf {R} $\n",
        "ist ihr gradient \n",
        "$\\displaystyle \\nabla f\\colon \\mathbf {R} ^{n}\\to \\mathbf {R} ^{n}$\n",
        " definiert als Spalten-Vektor ihrer partiellen Ableitungen in einem Punkt \n",
        "$\\displaystyle \\mathrm {p} =(x_{1},\\ldots ,x_{n})$:\n",
        "\n",
        "$\\displaystyle \\nabla f(p)={\\begin{bmatrix}{\\frac {\\partial f}{\\partial x_{1}}}(p)\\\\\\vdots \\\\{\\frac {\\partial f}{\\partial x_{n}}}(p)\\end{bmatrix}}.$\n",
        "\n",
        "**Gegeben:**\n",
        "Eine Funktion mit 2 unabhängigen Variablen $x$ und $y$: $f(x,y)= e^{3x} + ln(5y)$\n",
        "\n",
        "**Bestimmen Sie:**\n",
        "Den Gradienten der o.a. Funktion im Punkt $\\mathrm {p} = (x, y)$ mit  $x = 0, y = 1$:\n",
        "\n",
        "$\\displaystyle \\nabla f(0,1)={\\begin{bmatrix}{\\frac {\\partial f}{\\partial x}}(0,1)\\\\{\\frac {\\partial f}{\\partial y}}(0,1)\\end{bmatrix}}.$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNYmIC03DVTB"
      },
      "source": [
        "*Hinweis:* Berechnen Sie den Gradienten zunächst manuell auf Papier.\n",
        "\n",
        "***Bitte, die Zahlen innerhalb der Klammern durch Komma getrennt eingeben:***\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z-KrajRJwPQ"
      },
      "source": [
        "# Comment Cédric Moullet:\n",
        "# Derivative according to x of exp(3x) is 3exp(3x)\n",
        "# Derivative according to y of ln(5y) is 1/y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YemNTwCxSPbV",
        "cellView": "form"
      },
      "source": [
        "Gradient = \"[  3,1  ]\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YZoZrXUzt05"
      },
      "source": [
        "##**2 Dense Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ4FSxszxNLN"
      },
      "source": [
        "### Aufgabe 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyTaes7SgWo7"
      },
      "source": [
        "**Gegeben:** \n",
        "\n",
        "$y = X^3 \\cdot W + b + noise$\n",
        "\n",
        "mit\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "& y && - && Output/Label \\\\\n",
        "& X && - && Input Data-Matrix\\\\\n",
        "& W_{true} && - && Gewichte-Matrix\\\\\n",
        "& b_{true} && - && Bias\\\\\n",
        "& noise && - && Noise\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "und folgenden Parametern:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jOUmUdSX0Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb208ab-b7bb-4b81-ece7-b9c1133bdf72"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.nn import relu, tanh\n",
        "import numpy as np\n",
        "\n",
        "# Definition der Daten\n",
        "\n",
        "# seed\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "INPUT_SIZE = 5\n",
        "OUTPUT_SIZE = 1\n",
        "\n",
        "TRUE_W = tf.Variable(tf.random.normal((INPUT_SIZE, OUTPUT_SIZE)), name='w')\n",
        "TRUE_B = tf.Variable(tf.zeros(OUTPUT_SIZE, dtype=tf.float32), name='b')\n",
        "\n",
        "NUM_EXAMPLES = 1000\n",
        "\n",
        "# A vector of random x values\n",
        "x = tf.random.normal(shape=[NUM_EXAMPLES, INPUT_SIZE])\n",
        "x_test = tf.random.normal(shape=[NUM_EXAMPLES, INPUT_SIZE])\n",
        "\n",
        "# Generate some noise\n",
        "noise = tf.random.normal(shape=[NUM_EXAMPLES, OUTPUT_SIZE])\n",
        "noise_test = tf.random.normal(shape=[NUM_EXAMPLES, OUTPUT_SIZE])\n",
        "\n",
        "# Calculate y\n",
        "y = x**3 @ TRUE_W + TRUE_B + noise\n",
        "y_test = x_test**3 @ TRUE_W + TRUE_B + noise_test\n",
        "print(f\"input-shape:{x.shape}, output-shape:{y.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input-shape:(1000, 5), output-shape:(1000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtlORQr4jSUC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "abfb0b0f-ba84-4822-e141-5cf3f2d32c48"
      },
      "source": [
        "# Plot all the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x_test[:,0], y_test[:,0], c=\"b\")\n",
        "plt.scatter(x_test[:,1], y_test[:,0], c=\"r\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wawI7Z1jD9R"
      },
      "source": [
        "\n",
        "**Wir möchten nun die wahren Gewichte-Matrix und Bias-Vektor mit Hilfe eines Dense Neuronal Networks bestimmen.**\n",
        "\n",
        "####**Aufgabe 2.1:** In der ```MyModel``` Klasse initialisieren Sie bitte Gewichte und Biases für **2 (zwei) Hidden Layer** und das **Output-Layer** eines Dense Networks mit:\n",
        "**Hidden 1: 10 Neuronen**\n",
        "\n",
        "**Hidden 2: 8 Neuronen**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1H13BKQFIhe"
      },
      "source": [
        "####**Aufgabe 2.2:** In der ```MyModel``` Klasse definieren Sie die \\_call_ Funktion:\n",
        "```\n",
        "def __call__(self, x)\n",
        "```\n",
        "Vrewenden sie dabei die ***tanh*** Aktivierungs-Funktion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvLu5aC_IZD7"
      },
      "source": [
        "####**Aufgabe 2.3:** Erzeugen Sie eine Model-Instanz und verifizieren Sie diese mit\n",
        "\n",
        "```\n",
        "model(x).numpy()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpaXt4aqFlLK"
      },
      "source": [
        "\n",
        "####**Aufgabe 2.4:** Printen Sie die **Namen, Shapes und Werte** von allen Model-Variablen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REBFwSW7Fld7"
      },
      "source": [
        "####**Aufgabe 2.5:** Wieviele **neue Gewichte** werden erzeugt, wenn Sie die Anzahl der Neuronen vom Hidden 2 vedoppeln, d.h. für **Hidden Layer 2 - 16 Neuronen** anlegen? Geben Sie die Anzahl der zusätzlichen Gewichte **nur für den Layer 2** aus.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hinweis: Die Veränderung der Anzahl der Output-Neuronen eines Layers hat zwangsweise den Einfluss auch auf das Gewichte-Shape des unterstehenden Layers. Daher gilt die Frage einfachheitshalber nur für den selben Layer 2.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "wqVVYcTuvcx7"
      },
      "source": [
        "Anzahl_Neuer_Gewichte =  80#@param {type:\"number\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHR-G8A2KUKu"
      },
      "source": [
        "####**Aufgabe 2.6:** Warum wird hier ein anderer Seed verwendet, als im vorherigen Code-Abschnitt \"Definition der Daten\"? Beschreiben Sie die Ursache mit eigenen Worten in einem Satz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xRV6zdtPLxWs"
      },
      "source": [
        "Ursache = \"With this, the generated data are completely independent of the weights and biases \" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aWWFGvxjJD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf77f25-7156-4115-944a-d04b0a929870"
      },
      "source": [
        "# seed\n",
        "tf.random.set_seed(5678)\n",
        "\n",
        "class MyModel(tf.Module):\n",
        "  def __init__(self, input_size, output_size, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.INPUT_SIZE = input_size\n",
        "    self.OUTPUT_SIZE = output_size\n",
        "    self.LAYER_1_OUTPUT_SIZE = 10\n",
        "    self.LAYER_2_OUTPUT_SIZE = 8\n",
        "    \n",
        "    # Aufgabe 2.1 ##############################\n",
        "\n",
        "    self.w1 = tf.Variable(tf.random.normal((self.INPUT_SIZE, self.LAYER_1_OUTPUT_SIZE)), name='w1')\n",
        "    self.b1 = tf.Variable(tf.zeros(self.LAYER_1_OUTPUT_SIZE, dtype=tf.float32), name='b1')\n",
        "\n",
        "    self.w2 = tf.Variable(tf.random.normal((self.LAYER_1_OUTPUT_SIZE, self.LAYER_2_OUTPUT_SIZE)), name='w2')\n",
        "    self.b2 = tf.Variable(tf.zeros(self.LAYER_2_OUTPUT_SIZE, dtype=tf.float32), name='b2')\n",
        "\n",
        "    self.w3 = tf.Variable(tf.random.normal((self.LAYER_2_OUTPUT_SIZE, self.OUTPUT_SIZE)), name='w3')\n",
        "    self.b3 = tf.Variable(tf.zeros(self.OUTPUT_SIZE, dtype=tf.float32), name='b3')\n",
        "\n",
        "    ############################## Aufgabe 2.1 #\n",
        "\n",
        "\n",
        "  # Aufgabe 2.2 ##############################\n",
        "  def __call__(self, x):\n",
        "     \n",
        "     # Code Aufgabe 2.2 hier\n",
        "\n",
        "    x_1 = tanh(x @ self.w1 + self.b1)\n",
        "    x_2 = tanh(x_1 @ self.w2 + self.b2)\n",
        "    x_out = x_2 @ self.w3 + self.b3\n",
        "    return x_out\n",
        "\n",
        "    \n",
        "    return x_out\n",
        "  ############################## Aufgabe 2.2 #\n",
        "\n",
        "\n",
        "# Aufgabe 2.3 ##############################\n",
        "model = MyModel(5,1)\n",
        "# Verify the model works\n",
        "print(model(x).numpy())\n",
        "############################## Aufgabe 2.3 #\n",
        "\n",
        "\n",
        "# Aufgabe 2.4 ##############################\n",
        "# List the variables tf.modules's built-in variable aggregation.\n",
        "for var in model.variables:\n",
        "  print(\"Variable:\", var.name, var.shape)\n",
        "\n",
        "############################## Aufgabe 2.4 #\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-8.58749986e-01]\n",
            " [ 1.31477737e+00]\n",
            " [ 3.63991559e-01]\n",
            " [-1.20554996e+00]\n",
            " [ 1.37978220e+00]\n",
            " [ 9.03165638e-01]\n",
            " [ 2.47318864e+00]\n",
            " [ 1.99211359e+00]\n",
            " [ 1.33214211e+00]\n",
            " [-7.32538223e-01]\n",
            " [-1.95712614e+00]\n",
            " [ 1.30829227e+00]\n",
            " [-8.92019510e-01]\n",
            " [-9.97414589e-01]\n",
            " [-1.77908897e+00]\n",
            " [-2.06710577e+00]\n",
            " [ 1.63948488e+00]\n",
            " [ 1.97358882e+00]\n",
            " [-1.38302064e+00]\n",
            " [-9.73970175e-01]\n",
            " [ 4.00444835e-01]\n",
            " [-1.68196261e+00]\n",
            " [-2.07866955e+00]\n",
            " [ 2.06999826e+00]\n",
            " [-4.13087845e-01]\n",
            " [ 1.38423991e+00]\n",
            " [ 8.23145032e-01]\n",
            " [ 2.35481524e+00]\n",
            " [-1.06866193e+00]\n",
            " [-1.37312222e+00]\n",
            " [-1.33014011e+00]\n",
            " [-1.17862582e+00]\n",
            " [-1.96343625e+00]\n",
            " [-1.66161370e+00]\n",
            " [-1.42303443e+00]\n",
            " [ 1.44598007e-01]\n",
            " [-5.91014624e-01]\n",
            " [ 1.32053018e+00]\n",
            " [ 6.26714975e-02]\n",
            " [-2.37889826e-01]\n",
            " [ 1.68964756e+00]\n",
            " [ 1.35301614e+00]\n",
            " [-2.38522339e+00]\n",
            " [-1.23086190e+00]\n",
            " [ 3.04931939e-01]\n",
            " [ 1.39980078e+00]\n",
            " [-2.29747105e+00]\n",
            " [-1.26634502e+00]\n",
            " [ 5.98493993e-01]\n",
            " [-2.01882267e+00]\n",
            " [ 2.66856074e-01]\n",
            " [ 2.05842304e+00]\n",
            " [ 2.11562324e+00]\n",
            " [-1.72956944e+00]\n",
            " [-1.44638586e+00]\n",
            " [-7.10543334e-01]\n",
            " [-1.68563008e+00]\n",
            " [ 8.65476727e-02]\n",
            " [-2.19629526e-01]\n",
            " [-1.03270531e+00]\n",
            " [ 1.31667233e+00]\n",
            " [-4.66428757e-01]\n",
            " [-1.39281917e+00]\n",
            " [-1.84239626e+00]\n",
            " [-2.55593252e+00]\n",
            " [ 8.94997358e-01]\n",
            " [ 1.33101118e+00]\n",
            " [-1.27132773e+00]\n",
            " [-1.40690374e+00]\n",
            " [-1.56085324e+00]\n",
            " [ 1.13307297e-01]\n",
            " [-9.90262628e-01]\n",
            " [ 4.38505083e-01]\n",
            " [-7.70262480e-01]\n",
            " [ 1.87627316e+00]\n",
            " [ 1.75558090e+00]\n",
            " [-2.15548754e+00]\n",
            " [ 2.10414457e+00]\n",
            " [ 1.35097528e+00]\n",
            " [-1.37454271e+00]\n",
            " [ 7.09429979e-02]\n",
            " [ 8.82724285e-01]\n",
            " [-2.09898591e+00]\n",
            " [ 1.69594872e+00]\n",
            " [-1.39358401e+00]\n",
            " [-1.43485594e+00]\n",
            " [ 2.40784049e+00]\n",
            " [ 7.47409225e-01]\n",
            " [ 2.28379154e+00]\n",
            " [-2.17018938e+00]\n",
            " [ 1.64632010e+00]\n",
            " [ 1.04007769e+00]\n",
            " [-1.70535445e-02]\n",
            " [ 7.89959073e-01]\n",
            " [ 1.07017982e+00]\n",
            " [ 1.60572410e+00]\n",
            " [-3.05121452e-01]\n",
            " [-9.74400043e-02]\n",
            " [ 1.32301807e+00]\n",
            " [ 3.31041574e-01]\n",
            " [-4.59704161e-01]\n",
            " [-7.52740145e-01]\n",
            " [ 1.63257289e+00]\n",
            " [-3.48342121e-01]\n",
            " [ 1.53047180e+00]\n",
            " [ 4.61402535e-01]\n",
            " [ 5.36948562e-01]\n",
            " [ 2.16324925e+00]\n",
            " [ 1.96882987e+00]\n",
            " [ 3.99011374e-02]\n",
            " [ 1.54227138e+00]\n",
            " [ 1.40942693e+00]\n",
            " [-1.42436087e+00]\n",
            " [-1.11520743e+00]\n",
            " [ 1.79047310e+00]\n",
            " [-1.73916459e+00]\n",
            " [ 1.64581120e-01]\n",
            " [ 1.78461027e+00]\n",
            " [-7.62694001e-01]\n",
            " [ 4.02683556e-01]\n",
            " [-1.14884281e+00]\n",
            " [ 7.66081035e-01]\n",
            " [ 1.23252296e+00]\n",
            " [-9.76743817e-01]\n",
            " [ 4.58797395e-01]\n",
            " [-3.07035893e-01]\n",
            " [-1.38495159e+00]\n",
            " [-8.88232052e-01]\n",
            " [ 1.37525749e+00]\n",
            " [-2.38296652e+00]\n",
            " [ 2.16081333e+00]\n",
            " [-1.19721323e-01]\n",
            " [-1.24908197e+00]\n",
            " [-1.00269449e+00]\n",
            " [-2.20760655e+00]\n",
            " [ 7.32078373e-01]\n",
            " [ 1.54214430e+00]\n",
            " [ 1.00685000e+00]\n",
            " [-1.02803922e+00]\n",
            " [-1.24693882e+00]\n",
            " [ 6.22353733e-01]\n",
            " [-1.91372067e-01]\n",
            " [ 1.37119079e+00]\n",
            " [ 1.34240043e+00]\n",
            " [ 1.76846623e+00]\n",
            " [ 1.55774641e+00]\n",
            " [ 1.80081594e+00]\n",
            " [ 1.90107226e+00]\n",
            " [-5.24740934e-01]\n",
            " [-1.59508276e+00]\n",
            " [-6.33731484e-01]\n",
            " [-1.63705802e+00]\n",
            " [ 7.68186927e-01]\n",
            " [-1.43914294e+00]\n",
            " [ 1.72392166e+00]\n",
            " [ 5.58462441e-01]\n",
            " [-1.53917170e+00]\n",
            " [-1.73529994e+00]\n",
            " [ 7.31859803e-01]\n",
            " [-9.17808056e-01]\n",
            " [-8.61912906e-01]\n",
            " [-1.75933790e+00]\n",
            " [-1.36166406e+00]\n",
            " [ 8.00083041e-01]\n",
            " [-1.74086690e+00]\n",
            " [-1.01369953e+00]\n",
            " [-1.51440430e+00]\n",
            " [ 1.23930573e+00]\n",
            " [ 1.03693020e+00]\n",
            " [ 1.45960093e+00]\n",
            " [-1.46107757e+00]\n",
            " [ 5.91865778e-02]\n",
            " [ 1.20521355e+00]\n",
            " [-1.39462018e+00]\n",
            " [ 1.74427533e+00]\n",
            " [-8.55093122e-01]\n",
            " [-1.17425525e+00]\n",
            " [-9.48435605e-01]\n",
            " [-1.20414734e+00]\n",
            " [-5.88400841e-01]\n",
            " [-1.77295971e+00]\n",
            " [ 1.50218832e+00]\n",
            " [ 1.52804494e+00]\n",
            " [-1.61490631e+00]\n",
            " [ 2.05304193e+00]\n",
            " [-1.06779432e+00]\n",
            " [-1.53487921e-01]\n",
            " [ 1.27472258e+00]\n",
            " [ 2.26834941e+00]\n",
            " [-1.39164484e+00]\n",
            " [ 2.31863901e-01]\n",
            " [-3.22526574e-01]\n",
            " [-1.46820045e+00]\n",
            " [ 2.38480258e+00]\n",
            " [ 8.67658019e-01]\n",
            " [-1.33549106e+00]\n",
            " [ 4.58432794e-01]\n",
            " [ 1.07505929e+00]\n",
            " [ 8.62838089e-01]\n",
            " [ 8.83739889e-01]\n",
            " [-5.96968174e-01]\n",
            " [-1.29619324e+00]\n",
            " [-1.94624305e-01]\n",
            " [ 7.50359297e-01]\n",
            " [-1.70807338e+00]\n",
            " [-1.44431126e+00]\n",
            " [ 1.57079911e+00]\n",
            " [-7.59985030e-01]\n",
            " [ 1.46660161e+00]\n",
            " [-1.64732802e+00]\n",
            " [ 1.55303717e+00]\n",
            " [ 1.28596067e+00]\n",
            " [-4.12418962e-01]\n",
            " [-1.68448424e+00]\n",
            " [-1.80687797e+00]\n",
            " [-7.48910904e-02]\n",
            " [ 8.97570431e-01]\n",
            " [ 1.95692742e+00]\n",
            " [ 4.62945044e-01]\n",
            " [-3.73498976e-01]\n",
            " [ 7.43921995e-01]\n",
            " [ 1.22032726e+00]\n",
            " [-1.47108936e+00]\n",
            " [ 1.16441798e+00]\n",
            " [-1.27391267e+00]\n",
            " [ 1.85905123e+00]\n",
            " [-1.37699139e+00]\n",
            " [ 1.43166518e+00]\n",
            " [-1.19286942e+00]\n",
            " [ 1.48915029e+00]\n",
            " [ 9.51648653e-02]\n",
            " [ 1.93993759e+00]\n",
            " [-1.27143383e+00]\n",
            " [-1.55389380e+00]\n",
            " [-2.08182907e+00]\n",
            " [-1.50525868e+00]\n",
            " [-1.22463202e+00]\n",
            " [-1.28613639e+00]\n",
            " [ 1.97182882e+00]\n",
            " [ 2.33914900e+00]\n",
            " [-1.06942821e+00]\n",
            " [-9.32006538e-02]\n",
            " [ 2.79326582e+00]\n",
            " [-1.64632344e+00]\n",
            " [-1.03925169e+00]\n",
            " [ 1.03035784e+00]\n",
            " [-7.59951174e-01]\n",
            " [-2.45420837e+00]\n",
            " [-1.35163963e+00]\n",
            " [-1.67299902e+00]\n",
            " [ 1.96774411e+00]\n",
            " [ 5.90624332e-01]\n",
            " [-1.56247389e+00]\n",
            " [-1.13193226e+00]\n",
            " [-8.33977342e-01]\n",
            " [-2.67987537e+00]\n",
            " [ 9.37076569e-01]\n",
            " [ 1.35039067e+00]\n",
            " [ 2.05124664e+00]\n",
            " [ 1.37087977e+00]\n",
            " [-2.38396347e-01]\n",
            " [ 1.27641535e+00]\n",
            " [-1.24719787e+00]\n",
            " [-1.78621972e+00]\n",
            " [-7.25354075e-01]\n",
            " [-8.51042688e-01]\n",
            " [ 5.13711274e-01]\n",
            " [-4.56643760e-01]\n",
            " [-4.26162809e-01]\n",
            " [-3.81421566e-01]\n",
            " [-1.43708336e+00]\n",
            " [ 3.99117053e-01]\n",
            " [-6.55205131e-01]\n",
            " [ 1.13844216e+00]\n",
            " [-1.58661437e+00]\n",
            " [-8.05811763e-01]\n",
            " [ 1.67833948e+00]\n",
            " [ 1.71244240e+00]\n",
            " [-1.15943623e+00]\n",
            " [ 9.46837783e-01]\n",
            " [ 9.10353482e-01]\n",
            " [-2.76252460e+00]\n",
            " [-6.71388984e-01]\n",
            " [-1.12318659e+00]\n",
            " [ 1.85297728e-02]\n",
            " [-1.24056065e+00]\n",
            " [ 9.12243485e-01]\n",
            " [-7.72307217e-02]\n",
            " [-6.92693949e-01]\n",
            " [ 1.71832585e+00]\n",
            " [ 1.12547326e+00]\n",
            " [-7.31980801e-03]\n",
            " [-3.95045817e-01]\n",
            " [ 1.26348448e+00]\n",
            " [-1.17965007e+00]\n",
            " [-2.38622618e+00]\n",
            " [ 1.07894683e+00]\n",
            " [ 3.08093607e-01]\n",
            " [ 6.64782882e-01]\n",
            " [ 1.11574972e+00]\n",
            " [-4.76400703e-01]\n",
            " [ 1.71971369e+00]\n",
            " [-4.85425889e-01]\n",
            " [-1.34734976e+00]\n",
            " [-1.46437156e+00]\n",
            " [-9.19131041e-01]\n",
            " [-8.84455681e-01]\n",
            " [-1.87518477e+00]\n",
            " [ 1.65721297e+00]\n",
            " [ 1.47979116e+00]\n",
            " [ 1.58853859e-01]\n",
            " [ 2.02255607e-01]\n",
            " [-1.77433944e+00]\n",
            " [-1.92061448e+00]\n",
            " [ 7.59443820e-01]\n",
            " [-7.96443403e-01]\n",
            " [ 1.14689827e-01]\n",
            " [-1.26936686e+00]\n",
            " [ 1.31442046e+00]\n",
            " [-6.12401962e-01]\n",
            " [-2.80526590e+00]\n",
            " [ 1.78518534e+00]\n",
            " [-1.42139363e+00]\n",
            " [ 1.53923559e+00]\n",
            " [-2.41008306e+00]\n",
            " [-7.06908882e-01]\n",
            " [-2.62111115e+00]\n",
            " [-8.87507081e-01]\n",
            " [-1.47606397e+00]\n",
            " [ 1.64688849e+00]\n",
            " [-2.33398867e+00]\n",
            " [-7.77996421e-01]\n",
            " [-2.45719686e-01]\n",
            " [-3.82264942e-01]\n",
            " [-7.72564411e-01]\n",
            " [-6.40829086e-01]\n",
            " [ 2.55484200e+00]\n",
            " [-4.43404764e-01]\n",
            " [ 4.24964994e-01]\n",
            " [-1.29067039e+00]\n",
            " [-1.49797511e+00]\n",
            " [-1.47625780e+00]\n",
            " [-8.41975629e-01]\n",
            " [-4.75206375e-01]\n",
            " [ 1.84641552e+00]\n",
            " [ 1.29082251e+00]\n",
            " [ 1.59036684e+00]\n",
            " [ 8.49891543e-01]\n",
            " [ 2.13993406e+00]\n",
            " [ 2.33504474e-01]\n",
            " [-1.35966015e+00]\n",
            " [-1.87782574e+00]\n",
            " [-7.43466616e-01]\n",
            " [ 2.26115316e-01]\n",
            " [ 9.24652874e-01]\n",
            " [-1.17579651e+00]\n",
            " [-9.90158260e-01]\n",
            " [-1.33739495e+00]\n",
            " [ 1.29187369e+00]\n",
            " [-1.47590685e+00]\n",
            " [-9.45207477e-01]\n",
            " [-1.66084659e+00]\n",
            " [-1.08023739e+00]\n",
            " [-1.34104991e+00]\n",
            " [-2.69681633e-01]\n",
            " [-1.73300755e+00]\n",
            " [ 1.56264043e+00]\n",
            " [ 1.06301904e-01]\n",
            " [-9.05148029e-01]\n",
            " [ 3.79448682e-01]\n",
            " [-1.71481371e+00]\n",
            " [-1.18869615e+00]\n",
            " [ 3.79985869e-01]\n",
            " [ 8.27373266e-01]\n",
            " [-1.23698545e+00]\n",
            " [-2.22947884e+00]\n",
            " [ 1.46736622e+00]\n",
            " [-3.84285659e-01]\n",
            " [ 4.62576568e-01]\n",
            " [ 1.82488525e+00]\n",
            " [-1.66733694e+00]\n",
            " [ 1.63663721e+00]\n",
            " [ 1.22357440e+00]\n",
            " [-9.77847338e-01]\n",
            " [-9.03959811e-01]\n",
            " [ 6.12388432e-01]\n",
            " [-4.62941855e-01]\n",
            " [ 5.91861159e-02]\n",
            " [-2.01800513e+00]\n",
            " [-9.95522738e-03]\n",
            " [-1.54893041e-01]\n",
            " [ 2.52129602e+00]\n",
            " [ 1.27649999e+00]\n",
            " [ 1.06745601e+00]\n",
            " [-1.09490550e+00]\n",
            " [ 1.53351471e-01]\n",
            " [ 1.46136522e+00]\n",
            " [ 8.21457565e-01]\n",
            " [ 9.03196454e-01]\n",
            " [ 2.70791602e+00]\n",
            " [-1.24226093e-01]\n",
            " [ 1.11622274e+00]\n",
            " [-1.27981961e-01]\n",
            " [-1.25834167e+00]\n",
            " [ 1.59192061e+00]\n",
            " [-1.63427973e+00]\n",
            " [ 4.65755731e-01]\n",
            " [-5.40531337e-01]\n",
            " [ 2.18634415e+00]\n",
            " [-1.20060205e+00]\n",
            " [ 6.89494610e-02]\n",
            " [ 9.63596106e-01]\n",
            " [-1.89362216e+00]\n",
            " [ 1.19771171e+00]\n",
            " [ 1.16576970e-01]\n",
            " [ 2.10749006e+00]\n",
            " [-2.21992779e+00]\n",
            " [ 2.36342478e+00]\n",
            " [-1.30327702e+00]\n",
            " [ 1.47390032e+00]\n",
            " [-1.25461781e+00]\n",
            " [ 1.62875450e+00]\n",
            " [-3.00923228e-01]\n",
            " [ 3.61164302e-01]\n",
            " [ 7.91390538e-01]\n",
            " [ 2.60924369e-01]\n",
            " [ 1.11942828e+00]\n",
            " [ 9.80872512e-02]\n",
            " [-1.83529747e+00]\n",
            " [ 2.23515511e+00]\n",
            " [-5.64606786e-01]\n",
            " [-1.67461395e+00]\n",
            " [-9.80664849e-01]\n",
            " [-5.81679702e-01]\n",
            " [-1.21146345e+00]\n",
            " [-1.07136893e+00]\n",
            " [ 1.94712472e+00]\n",
            " [ 1.28500748e+00]\n",
            " [ 1.68834698e+00]\n",
            " [ 1.74142241e+00]\n",
            " [ 7.44472861e-01]\n",
            " [ 1.34343350e+00]\n",
            " [-1.18738043e+00]\n",
            " [-8.72871876e-01]\n",
            " [ 1.57687640e+00]\n",
            " [-2.85565853e-03]\n",
            " [-1.20278645e+00]\n",
            " [ 2.07323933e+00]\n",
            " [ 1.52014685e+00]\n",
            " [ 9.61915970e-01]\n",
            " [-1.36530280e+00]\n",
            " [-2.04608893e+00]\n",
            " [-2.64449000e+00]\n",
            " [-1.79189408e+00]\n",
            " [-1.69185710e+00]\n",
            " [ 9.96435940e-01]\n",
            " [-1.22114229e+00]\n",
            " [ 1.28075480e+00]\n",
            " [-1.10840786e+00]\n",
            " [-2.09175968e+00]\n",
            " [-1.64944637e+00]\n",
            " [ 7.15689063e-01]\n",
            " [ 2.09333420e+00]\n",
            " [-1.49042928e+00]\n",
            " [-4.59631801e-01]\n",
            " [-1.35727572e+00]\n",
            " [-1.31838775e+00]\n",
            " [-2.14976501e+00]\n",
            " [ 5.37252069e-01]\n",
            " [-9.54687357e-01]\n",
            " [ 2.29109430e+00]\n",
            " [ 9.50611770e-01]\n",
            " [ 6.53244257e-01]\n",
            " [ 1.63977712e-01]\n",
            " [-1.22019231e-01]\n",
            " [ 1.10264957e+00]\n",
            " [-1.10753250e+00]\n",
            " [-4.00892615e-01]\n",
            " [ 2.04920650e+00]\n",
            " [ 1.05630934e-01]\n",
            " [-8.95616651e-01]\n",
            " [-5.26203752e-01]\n",
            " [ 1.74377751e+00]\n",
            " [ 1.49424124e+00]\n",
            " [ 1.64056718e+00]\n",
            " [-1.91456008e+00]\n",
            " [ 3.79022360e-02]\n",
            " [ 2.22299075e+00]\n",
            " [ 4.59167957e-01]\n",
            " [-3.08733821e-01]\n",
            " [ 1.50655830e+00]\n",
            " [ 1.66559243e+00]\n",
            " [ 2.28925037e+00]\n",
            " [ 1.43252659e+00]\n",
            " [-1.32214737e+00]\n",
            " [ 1.34095657e+00]\n",
            " [-1.28643322e+00]\n",
            " [ 1.11534691e+00]\n",
            " [ 9.41564679e-01]\n",
            " [-1.28285646e+00]\n",
            " [ 1.81136417e+00]\n",
            " [ 8.63871932e-01]\n",
            " [-2.18417138e-01]\n",
            " [-7.18416750e-01]\n",
            " [ 1.96025801e+00]\n",
            " [ 5.01250148e-01]\n",
            " [ 1.47835493e+00]\n",
            " [ 2.52858448e+00]\n",
            " [-1.78215861e+00]\n",
            " [-1.97928262e+00]\n",
            " [-2.20802021e+00]\n",
            " [ 1.85205555e+00]\n",
            " [ 1.68001533e+00]\n",
            " [ 1.31119847e+00]\n",
            " [-5.75553298e-01]\n",
            " [-1.30595469e+00]\n",
            " [ 1.50985384e+00]\n",
            " [-1.48418516e-01]\n",
            " [ 8.64380658e-01]\n",
            " [-8.53682041e-01]\n",
            " [-1.47219539e+00]\n",
            " [-2.53300428e+00]\n",
            " [ 9.11351800e-01]\n",
            " [-2.41361952e+00]\n",
            " [ 1.59036040e+00]\n",
            " [ 1.14689684e+00]\n",
            " [-2.23910952e+00]\n",
            " [ 9.96924520e-01]\n",
            " [ 1.17537320e-01]\n",
            " [ 1.21400023e+00]\n",
            " [ 8.76372099e-01]\n",
            " [-1.46446168e+00]\n",
            " [-1.44568634e+00]\n",
            " [ 1.58390725e+00]\n",
            " [-1.35083318e+00]\n",
            " [-7.25641906e-01]\n",
            " [ 1.23539948e+00]\n",
            " [-1.46304548e-01]\n",
            " [-4.47936684e-01]\n",
            " [ 6.20047510e-01]\n",
            " [-1.78203154e+00]\n",
            " [ 1.04982626e+00]\n",
            " [-1.20802462e+00]\n",
            " [-1.27281117e+00]\n",
            " [ 1.01510334e+00]\n",
            " [-7.70200849e-01]\n",
            " [ 1.20697463e+00]\n",
            " [-1.47258484e+00]\n",
            " [-5.87875068e-01]\n",
            " [-8.08769643e-01]\n",
            " [ 1.20325029e+00]\n",
            " [-7.92490959e-01]\n",
            " [ 2.18287516e+00]\n",
            " [ 1.58919597e+00]\n",
            " [-5.15535355e-01]\n",
            " [-1.71244788e+00]\n",
            " [-2.53733706e+00]\n",
            " [-7.29432702e-03]\n",
            " [-1.22774208e+00]\n",
            " [-1.49779260e+00]\n",
            " [-2.73458242e-01]\n",
            " [ 2.58742142e+00]\n",
            " [-3.26407552e-01]\n",
            " [ 1.61299491e+00]\n",
            " [-1.26329172e+00]\n",
            " [-1.65586066e+00]\n",
            " [ 2.46568346e+00]\n",
            " [-1.66621363e+00]\n",
            " [ 1.71257973e+00]\n",
            " [ 7.04639673e-01]\n",
            " [ 2.22717977e+00]\n",
            " [-1.06124437e+00]\n",
            " [ 1.45910096e+00]\n",
            " [ 1.83835351e+00]\n",
            " [-1.90278637e+00]\n",
            " [-1.14224821e-01]\n",
            " [-9.16776359e-01]\n",
            " [-9.89818811e-01]\n",
            " [-1.43340015e+00]\n",
            " [-2.35043168e+00]\n",
            " [-8.08254480e-02]\n",
            " [ 1.90531516e+00]\n",
            " [-1.24040127e+00]\n",
            " [ 9.26198781e-01]\n",
            " [ 8.22230577e-01]\n",
            " [-9.39902544e-01]\n",
            " [-3.29954624e-01]\n",
            " [-1.34857923e-01]\n",
            " [ 6.66500449e-01]\n",
            " [ 6.46962881e-01]\n",
            " [-3.80385220e-02]\n",
            " [ 1.69644547e+00]\n",
            " [-1.55142903e+00]\n",
            " [-1.83984947e+00]\n",
            " [ 1.74073148e+00]\n",
            " [-1.17155147e+00]\n",
            " [-1.69657719e+00]\n",
            " [-1.87230706e-02]\n",
            " [ 1.72544885e+00]\n",
            " [ 6.47025228e-01]\n",
            " [ 1.77657568e+00]\n",
            " [-5.19936085e-01]\n",
            " [ 1.90367329e+00]\n",
            " [ 1.29050875e+00]\n",
            " [ 1.14001083e+00]\n",
            " [ 6.62749529e-01]\n",
            " [ 1.99789965e+00]\n",
            " [ 1.30969095e+00]\n",
            " [ 7.76649714e-02]\n",
            " [ 1.69605780e+00]\n",
            " [ 8.38781774e-01]\n",
            " [-1.14434338e+00]\n",
            " [ 2.60743523e+00]\n",
            " [-1.07645774e+00]\n",
            " [-1.54354811e+00]\n",
            " [-2.02945852e+00]\n",
            " [ 4.53362674e-01]\n",
            " [ 1.12791157e+00]\n",
            " [ 1.39959431e+00]\n",
            " [ 2.24744701e+00]\n",
            " [-1.23629880e+00]\n",
            " [ 7.64590979e-01]\n",
            " [ 1.18725777e-01]\n",
            " [-4.48437363e-01]\n",
            " [ 1.98078811e+00]\n",
            " [-1.98868930e+00]\n",
            " [-5.62101126e-01]\n",
            " [-6.87483132e-01]\n",
            " [ 1.23064470e+00]\n",
            " [ 5.08081257e-01]\n",
            " [ 1.78926635e+00]\n",
            " [ 1.41822147e+00]\n",
            " [-1.31521583e+00]\n",
            " [ 1.55595326e+00]\n",
            " [-9.97008085e-01]\n",
            " [-2.63146830e+00]\n",
            " [ 9.96196866e-01]\n",
            " [-1.43293285e+00]\n",
            " [ 1.57385528e+00]\n",
            " [ 7.23241627e-01]\n",
            " [-1.89125133e+00]\n",
            " [ 1.35398054e+00]\n",
            " [ 8.34764957e-01]\n",
            " [ 1.57191133e+00]\n",
            " [ 1.51749647e+00]\n",
            " [ 4.77774143e-01]\n",
            " [-1.67387497e+00]\n",
            " [ 7.90843070e-01]\n",
            " [-1.26492333e+00]\n",
            " [ 1.71820545e+00]\n",
            " [-2.97644830e+00]\n",
            " [-1.68662727e+00]\n",
            " [ 2.31800377e-01]\n",
            " [-1.56308877e+00]\n",
            " [-1.49503410e-01]\n",
            " [ 1.30333233e+00]\n",
            " [ 1.49071300e+00]\n",
            " [-1.41078901e+00]\n",
            " [-1.53837109e+00]\n",
            " [-9.80698705e-01]\n",
            " [ 1.83716655e+00]\n",
            " [-1.04967189e+00]\n",
            " [ 4.65971410e-01]\n",
            " [ 2.31968117e+00]\n",
            " [ 1.47659087e+00]\n",
            " [ 3.16888571e-01]\n",
            " [-1.05178022e+00]\n",
            " [-2.45054960e-01]\n",
            " [-1.23325610e+00]\n",
            " [-1.99102163e-01]\n",
            " [ 1.45126390e+00]\n",
            " [-1.51439142e+00]\n",
            " [ 1.60195994e+00]\n",
            " [ 9.64993238e-01]\n",
            " [-2.69982994e-01]\n",
            " [-1.21399045e+00]\n",
            " [ 1.08184624e+00]\n",
            " [ 2.51265717e+00]\n",
            " [-1.02757692e+00]\n",
            " [ 1.50801229e+00]\n",
            " [ 1.33076453e+00]\n",
            " [-1.31947160e+00]\n",
            " [ 1.00920677e+00]\n",
            " [ 1.34721458e+00]\n",
            " [-2.77971148e-01]\n",
            " [-8.04264307e-01]\n",
            " [-1.30012715e+00]\n",
            " [-7.87414253e-01]\n",
            " [ 8.23780060e-01]\n",
            " [-1.19924831e+00]\n",
            " [-1.35656834e+00]\n",
            " [ 2.16869187e+00]\n",
            " [-3.46250683e-01]\n",
            " [-7.84312189e-01]\n",
            " [-7.65098691e-01]\n",
            " [ 1.72714245e+00]\n",
            " [ 1.09441078e+00]\n",
            " [ 1.63245249e+00]\n",
            " [-1.99002242e+00]\n",
            " [ 1.70437217e+00]\n",
            " [-1.62124944e+00]\n",
            " [ 1.61070955e+00]\n",
            " [-8.39338660e-01]\n",
            " [-1.18860674e+00]\n",
            " [-1.09030402e+00]\n",
            " [-1.24199343e+00]\n",
            " [-1.15806341e-01]\n",
            " [ 1.15448689e+00]\n",
            " [ 2.05934787e+00]\n",
            " [-1.48583198e+00]\n",
            " [ 1.15874588e-01]\n",
            " [-6.01608902e-02]\n",
            " [ 9.99683738e-01]\n",
            " [-6.12008631e-01]\n",
            " [-1.64375484e+00]\n",
            " [-1.08083463e+00]\n",
            " [-1.49626851e+00]\n",
            " [-1.24040413e+00]\n",
            " [ 3.56119394e-01]\n",
            " [-1.36098003e+00]\n",
            " [ 1.16524267e+00]\n",
            " [ 2.31649494e+00]\n",
            " [-8.51813555e-01]\n",
            " [ 3.23312354e+00]\n",
            " [-2.41796827e+00]\n",
            " [ 1.55538344e+00]\n",
            " [ 2.66536117e+00]\n",
            " [-1.38271880e+00]\n",
            " [-1.19223082e+00]\n",
            " [ 1.58095193e+00]\n",
            " [-1.53490019e+00]\n",
            " [ 1.43847609e+00]\n",
            " [ 4.88356948e-02]\n",
            " [ 1.01252127e+00]\n",
            " [-7.95949817e-01]\n",
            " [ 7.35192060e-01]\n",
            " [-2.18008471e+00]\n",
            " [-1.02811754e+00]\n",
            " [-4.85834122e-01]\n",
            " [-4.07967001e-01]\n",
            " [ 1.48313940e+00]\n",
            " [ 1.33285451e+00]\n",
            " [-8.45709860e-01]\n",
            " [ 1.27192533e+00]\n",
            " [-1.61352158e+00]\n",
            " [ 4.29614484e-01]\n",
            " [ 2.42804527e+00]\n",
            " [ 2.23304248e+00]\n",
            " [-5.44734716e-01]\n",
            " [-1.51781046e+00]\n",
            " [ 6.29248321e-01]\n",
            " [-1.07023096e+00]\n",
            " [ 2.73648620e-01]\n",
            " [-1.64491534e-02]\n",
            " [-1.24387133e+00]\n",
            " [-1.21869683e+00]\n",
            " [-1.77255321e+00]\n",
            " [-5.41131258e-01]\n",
            " [-9.29869592e-01]\n",
            " [ 1.53214169e+00]\n",
            " [ 1.86108053e-02]\n",
            " [-1.58249688e+00]\n",
            " [ 1.62715054e+00]\n",
            " [-9.83903050e-01]\n",
            " [-2.61067033e-01]\n",
            " [ 1.23006380e+00]\n",
            " [ 1.41740131e+00]\n",
            " [ 1.07622516e+00]\n",
            " [-2.18187094e+00]\n",
            " [-8.34008574e-01]\n",
            " [-1.57351172e+00]\n",
            " [-2.39654064e+00]\n",
            " [ 1.41526008e+00]\n",
            " [-1.00613177e+00]\n",
            " [ 1.49901342e+00]\n",
            " [ 1.18270206e+00]\n",
            " [ 2.84591377e-01]\n",
            " [ 1.39689112e+00]\n",
            " [-1.85355783e+00]\n",
            " [-1.13958466e+00]\n",
            " [ 1.26451898e+00]\n",
            " [-1.29405379e+00]\n",
            " [-1.35603309e+00]\n",
            " [-9.18800175e-01]\n",
            " [ 2.25790203e-01]\n",
            " [ 9.73164082e-01]\n",
            " [ 1.91651434e-01]\n",
            " [-1.18511808e+00]\n",
            " [ 5.65006495e-01]\n",
            " [-5.25520742e-01]\n",
            " [-1.23250413e+00]\n",
            " [-2.32105756e+00]\n",
            " [-2.94934034e+00]\n",
            " [ 1.15000904e+00]\n",
            " [-1.42729902e+00]\n",
            " [-1.48535848e+00]\n",
            " [ 1.93166280e+00]\n",
            " [-1.85711122e+00]\n",
            " [ 7.16619134e-01]\n",
            " [ 2.14093626e-01]\n",
            " [-1.63908315e+00]\n",
            " [-3.11605245e-01]\n",
            " [ 1.39691544e+00]\n",
            " [-1.91717601e+00]\n",
            " [-1.66415370e+00]\n",
            " [-9.67375636e-01]\n",
            " [-1.66930521e+00]\n",
            " [-8.63832831e-01]\n",
            " [ 9.83534455e-01]\n",
            " [ 2.18686247e+00]\n",
            " [ 5.14905691e-01]\n",
            " [ 1.70487261e+00]\n",
            " [ 1.81439435e+00]\n",
            " [-1.29593349e+00]\n",
            " [-1.63805437e+00]\n",
            " [ 1.50351906e+00]\n",
            " [ 3.93719077e-01]\n",
            " [-5.83083034e-02]\n",
            " [-5.41610122e-02]\n",
            " [-1.42053819e+00]\n",
            " [ 1.49979615e+00]\n",
            " [ 7.38022447e-01]\n",
            " [ 1.30691135e+00]\n",
            " [ 1.33951139e+00]\n",
            " [-1.67238450e+00]\n",
            " [ 1.42124653e+00]\n",
            " [-1.08354199e+00]\n",
            " [-3.66396874e-01]\n",
            " [-1.47995722e+00]\n",
            " [ 2.05653620e+00]\n",
            " [ 3.18499804e-01]\n",
            " [ 3.59843075e-01]\n",
            " [-1.99120736e+00]\n",
            " [ 2.45320654e+00]\n",
            " [ 8.74390125e-01]\n",
            " [ 1.03245258e+00]\n",
            " [-4.26835656e-01]\n",
            " [ 5.04991829e-01]\n",
            " [-1.52854729e+00]\n",
            " [-1.86206126e+00]\n",
            " [ 1.62607765e+00]\n",
            " [-1.21637678e+00]\n",
            " [ 1.13311267e+00]\n",
            " [ 1.36440086e+00]\n",
            " [-4.61162090e-01]\n",
            " [-5.95849931e-01]\n",
            " [ 4.64873850e-01]\n",
            " [ 1.56784785e+00]\n",
            " [-8.19065094e-01]\n",
            " [-2.02508235e+00]\n",
            " [ 1.10162884e-01]\n",
            " [-1.29348314e+00]\n",
            " [ 1.15419626e+00]\n",
            " [-4.09785032e-01]\n",
            " [-1.21321738e+00]\n",
            " [ 2.47396755e+00]\n",
            " [-1.52376318e+00]\n",
            " [ 1.23724341e+00]\n",
            " [ 1.33308077e+00]\n",
            " [-1.50411272e+00]\n",
            " [-2.57414055e+00]\n",
            " [ 7.35876322e-01]\n",
            " [ 1.21822584e+00]\n",
            " [-1.37770045e+00]\n",
            " [ 1.86756468e+00]\n",
            " [-3.72791529e-01]\n",
            " [-1.05964884e-01]\n",
            " [ 8.67874146e-01]\n",
            " [-1.25399232e-01]\n",
            " [ 7.02073157e-01]\n",
            " [-1.15302563e+00]\n",
            " [ 1.52244341e+00]\n",
            " [-1.05187297e-03]\n",
            " [ 1.59113634e+00]\n",
            " [ 1.50544739e+00]\n",
            " [-1.38440824e+00]\n",
            " [-1.37639451e+00]\n",
            " [-1.04847372e+00]\n",
            " [-1.88997531e+00]\n",
            " [ 1.88391185e+00]\n",
            " [ 1.97160161e+00]\n",
            " [-1.27954340e+00]\n",
            " [-1.54755127e+00]\n",
            " [-9.16855693e-01]\n",
            " [-1.00799656e+00]\n",
            " [-1.04611194e+00]\n",
            " [ 1.51590562e+00]\n",
            " [-1.66066790e+00]\n",
            " [-2.16381860e+00]\n",
            " [ 4.83381748e-01]\n",
            " [ 1.37778509e+00]\n",
            " [ 5.01984239e-01]\n",
            " [ 1.60365152e+00]\n",
            " [-3.84238064e-02]\n",
            " [ 7.05495536e-01]\n",
            " [-2.10323095e+00]\n",
            " [-1.31511402e+00]\n",
            " [-1.44238782e+00]\n",
            " [ 8.64185452e-01]\n",
            " [ 1.59412813e+00]\n",
            " [ 1.16698682e+00]\n",
            " [ 1.05205512e+00]\n",
            " [-1.72104931e+00]\n",
            " [ 1.58556080e+00]\n",
            " [ 1.51822245e+00]\n",
            " [-2.82104731e+00]\n",
            " [-6.53719544e-01]\n",
            " [ 1.18675029e+00]\n",
            " [-1.92117262e+00]\n",
            " [-1.40868556e+00]\n",
            " [-1.79092216e+00]\n",
            " [-1.39728737e+00]\n",
            " [-5.93572378e-01]\n",
            " [ 2.92834592e+00]\n",
            " [-5.31890035e-01]\n",
            " [-1.56575012e+00]\n",
            " [ 2.35059643e+00]\n",
            " [-1.06844342e+00]\n",
            " [-2.75363541e+00]\n",
            " [-1.43125665e+00]\n",
            " [ 8.51593018e-02]\n",
            " [ 2.29287565e-01]\n",
            " [-1.68295419e+00]\n",
            " [-6.20492399e-01]\n",
            " [ 6.00601196e-01]\n",
            " [ 1.62119985e+00]\n",
            " [ 1.03633952e+00]\n",
            " [-7.19343185e-01]\n",
            " [-5.24471223e-01]\n",
            " [-1.44527495e+00]\n",
            " [ 1.41364288e+00]\n",
            " [ 1.09816670e+00]\n",
            " [ 2.30747557e+00]\n",
            " [ 8.65998745e-01]\n",
            " [ 1.82759166e-01]\n",
            " [ 4.48970735e-01]\n",
            " [-2.44842958e+00]\n",
            " [ 5.33748269e-02]\n",
            " [-1.71354389e+00]\n",
            " [-1.14177895e+00]\n",
            " [-1.80503058e+00]\n",
            " [-3.48810375e-01]\n",
            " [ 2.27615762e+00]\n",
            " [-1.11590934e+00]\n",
            " [ 2.47394443e-02]\n",
            " [ 2.93998778e-01]\n",
            " [-1.14478898e+00]\n",
            " [ 7.09539115e-01]\n",
            " [-1.21154785e+00]\n",
            " [-1.10626507e+00]\n",
            " [-2.16725492e+00]\n",
            " [ 2.49981308e+00]\n",
            " [-1.44662666e+00]\n",
            " [-3.97299081e-01]\n",
            " [ 1.33373380e+00]\n",
            " [-1.08177567e+00]\n",
            " [-8.00507545e-01]\n",
            " [-1.51978660e+00]\n",
            " [-7.25603580e-01]\n",
            " [ 1.89544231e-01]\n",
            " [-1.69276381e+00]\n",
            " [ 1.75532842e+00]\n",
            " [ 1.31441045e+00]\n",
            " [ 1.10437453e+00]\n",
            " [-1.40325415e+00]\n",
            " [ 2.12367749e+00]\n",
            " [-1.77865374e+00]\n",
            " [ 7.25818634e-01]\n",
            " [ 2.08556008e+00]\n",
            " [ 1.17174864e+00]\n",
            " [-2.76089668e+00]\n",
            " [ 2.06821203e+00]\n",
            " [-5.70848584e-03]\n",
            " [ 6.14399195e-01]\n",
            " [-1.73666620e+00]\n",
            " [ 1.55674613e+00]\n",
            " [-5.11030138e-01]\n",
            " [ 1.47311008e+00]\n",
            " [-1.42458415e+00]\n",
            " [ 1.87188840e+00]\n",
            " [ 1.41408193e+00]\n",
            " [ 1.59989476e+00]\n",
            " [ 5.32697439e-02]\n",
            " [ 3.94920558e-01]\n",
            " [ 1.19789791e+00]\n",
            " [-4.28168684e-01]\n",
            " [-1.66966259e-01]\n",
            " [ 1.91782975e+00]\n",
            " [ 2.12832618e+00]\n",
            " [-1.49537826e+00]\n",
            " [ 7.25370467e-01]\n",
            " [-1.15701687e+00]\n",
            " [-4.02089715e-01]\n",
            " [-8.83043528e-01]\n",
            " [ 2.34763288e+00]\n",
            " [ 2.18908668e+00]\n",
            " [ 9.34072793e-01]\n",
            " [-1.80963206e+00]\n",
            " [ 8.27521443e-01]\n",
            " [ 9.95218396e-01]]\n",
            "Variable: b1:0 (10,)\n",
            "Variable: b2:0 (8,)\n",
            "Variable: b3:0 (1,)\n",
            "Variable: w1:0 (5, 10)\n",
            "Variable: w2:0 (10, 8)\n",
            "Variable: w3:0 (8, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHVgn5wbSMA9"
      },
      "source": [
        "####**Aufgabe 2.7:** Definieren Sie das Training-Loop für **2000 Epochs**.  Printen Sie die **Epoch Nummer** und den **Loss** alle **100 Epochs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIPOKnMfwhlS"
      },
      "source": [
        "\n",
        "\n",
        "####**Aufgabe 2.8:** Trainieren Sie das Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clybL2zHogM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af442635-9660-4669-fc80-0bcfbe2c5d24"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate=0.01)\n",
        "# This computes a single loss value for an entire batch\n",
        "def loss(target_y, predicted_y):\n",
        "  return tf.reduce_mean(tf.square(target_y - predicted_y))\n",
        "\n",
        "# Given a callable model, inputs, outputs, and a learning rate...\n",
        "def train(model, x, y, learning_rate):\n",
        "\n",
        "  with tf.GradientTape() as t:\n",
        "    # Trainable variables are automatically tracked by GradientTape\n",
        "    current_loss = loss(y, model(x))\n",
        "\n",
        "  # Use GradientTape to calculate the gradients with respect to W and b\n",
        "  grads = t.gradient(current_loss, model.trainable_variables)\n",
        "  opt.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "# Init Model\n",
        "model = MyModel(INPUT_SIZE, OUTPUT_SIZE)\n",
        "# Collect the history of W-values and b-values to plot later\n",
        "\n",
        "# Aufgabe 2.7 ##############################\n",
        "epochs = range(2000)\n",
        "# Define a training loop\n",
        "def training_loop(model, x, y):\n",
        "\n",
        "  for epoch in epochs:\n",
        "     # Update the model with the single giant batch\n",
        "    train(model, x, y, learning_rate=0.1)\n",
        "\n",
        "    current_loss = loss(y, model(x))\n",
        "    if (epoch % 100 == 0):\n",
        "      print(\"Epoch %2d: loss=%2.5f\" %\n",
        "          (epoch, current_loss))\n",
        "\n",
        "\n",
        "############################## Aufgabe 2.7 #\n",
        "    \n",
        "# Aufgabe 2.8 ####################\n",
        "# Do the training\n",
        "\n",
        "training_loop(model, x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0: loss=48.01633\n",
            "Epoch 100: loss=21.94885\n",
            "Epoch 200: loss=13.15014\n",
            "Epoch 300: loss=7.71759\n",
            "Epoch 400: loss=4.64107\n",
            "Epoch 500: loss=3.25050\n",
            "Epoch 600: loss=2.58602\n",
            "Epoch 700: loss=2.21390\n",
            "Epoch 800: loss=1.97154\n",
            "Epoch 900: loss=1.80127\n",
            "Epoch 1000: loss=1.66842\n",
            "Epoch 1100: loss=1.57218\n",
            "Epoch 1200: loss=1.49004\n",
            "Epoch 1300: loss=1.42588\n",
            "Epoch 1400: loss=1.35181\n",
            "Epoch 1500: loss=1.29470\n",
            "Epoch 1600: loss=1.24684\n",
            "Epoch 1700: loss=1.21354\n",
            "Epoch 1800: loss=1.17352\n",
            "Epoch 1900: loss=1.14382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46lr4GajBxey"
      },
      "source": [
        "####**Aufgabe 2.9:** Plotten Sie den Output des trainierten Models **$\\hat{y}_{test}$** vs. **Target Data** für den **Test Dataset**: $\\hat{y}_{test} = model(X_{test}) \\nobreakspace vs. \\nobreakspace y_{test}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGWejFnSz6Sw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1624d70e-6ba3-4896-cc51-8a4b27f72e35"
      },
      "source": [
        "# Aufgabe 2.9\n",
        "# Visualize how the trained model performs\n",
        "plt.scatter(x_test[:, 0], y_test[:, 0], c=\"b\")\n",
        "plt.scatter(x_test[:, 0], model(x_test)[:, 0], c=\"r\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcDzQuguTC0d"
      },
      "source": [
        "####**Aufgabe 2.10:** Berechnen Sie den Loss für den **Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzcfeFtwOl2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2feae8b9-b6e5-4149-9a60-925fc00f2348"
      },
      "source": [
        "# Aufgabe 2.10\n",
        "print(\"Current loss: %1.6f\" % loss(model(x), y).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current loss: 1.118439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ0MEls4z0Np"
      },
      "source": [
        "##**LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5x78TYSVkxv"
      },
      "source": [
        "### Aufgabe 3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IVNTmnZaJQR"
      },
      "source": [
        "Wir wollen jetzt ein LSTM Model auf einem Image-Dataset trainieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wrnEn1vayrA"
      },
      "source": [
        "####**Aufgabe 3.1:** Ist das überhaupt möglich?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OKmEr3_ca9Ln"
      },
      "source": [
        "Antwort = \"ja\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uOO5TSmbPwU"
      },
      "source": [
        "####**Aufgabe 3.2:** Ist das optimal?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TjEjWi17bZNU"
      },
      "source": [
        "Antwort = \"nein\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhLlyI4nfylt"
      },
      "source": [
        "####**Aufgabe 3.3:** Bei welcher Art von Image-Daten wäre die Verwendung von LSTM-Layers durchaus angebracht? Bitte, eine am besten geignete Option auswählen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3F98WDEgBGj",
        "cellView": "form"
      },
      "source": [
        "Antwort = \"Bild Sequenzen (Games, Film)\" #@param [\"Mond Bilder\", \"Bild Sequenzen (Games, Film)\", \"Fotos von Justin Bieber\", \"please select\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzbvV_z88CFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8506f93-6241-46a8-d950-444cb81eda33"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Wir laden hier das Fashion Mnist Dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sH1F3kJ7Q3c"
      },
      "source": [
        "\n",
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `train_images` and `train_labels` arrays are the *training set*—the data the model uses to learn.\n",
        "* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents. Each image is mapped to a single label:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piIdCb1eDTeE"
      },
      "source": [
        "$\n",
        "\\begin{array}{|c|l|}\n",
        "  \\hline \\hline\n",
        "  Label & Class\\\\\n",
        "  \\hline\n",
        "  \\hline\t\t\t\n",
        "  0 & T-shirt/top \\\\\\hline\n",
        "  1 & Trouser \\\\\\hline\n",
        "  2 &  Pullover \\\\\\hline\n",
        "  3 &  Dress \\\\\\hline\n",
        "  4 &  Coat \\\\\\hline\n",
        "  5 &  Sandal \\\\\\hline\n",
        "  6 &  Shirt \\\\\\hline\n",
        "  7 &  Sneaker \\\\\\hline\n",
        "  8 &  Bag \\\\\\hline\n",
        "  9 &  Ankle \\nobreakspace Boot \\\\\\hline\n",
        "  \\hline  \n",
        "\\end{array}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xboXQw8OWPGj"
      },
      "source": [
        "####**Aufgabe 3.4:** Verifizieren Sie die Unique-Labels in dem Train und Test Datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGyW9MQc8ZCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452e1cd8-01cf-415a-f90d-6ed138c79b73"
      },
      "source": [
        "print(np.unique(train_labels))\n",
        "print(np.unique(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN8KPAqrR1YJ"
      },
      "source": [
        "# Comment Cédric Moullet: 10 possible labels are available in the train and test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SXQbOPcWzyd"
      },
      "source": [
        "####**Aufgabe 3.5:** Skalieren Sie die Image Daten auf den Werte-Bereich (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uspXZCPgVU1P"
      },
      "source": [
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lc7X81QSVAs",
        "outputId": "285857c4-e9d4-406a-80f6-051ac859c16f"
      },
      "source": [
        "print(np.max(train_images))\n",
        "print(np.max(test_images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2JOsiT93PkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f007727-97e6-4627-ccf7-115a16734b5e"
      },
      "source": [
        "# shapes\n",
        "train_images.shape, test_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w85sfb2z7hk6"
      },
      "source": [
        "####**Aufgabe 3.6:** Die Image-Arrays aus Fashion-Mnist Dataset haben Shape (28, 28). Angenommen, ein Image wäre vom Shape **(28, 64)**. Wieviele **\"Features\"** und **\"Timesteps\"** hätte ein solches Image?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vBCNj9zFcsqc"
      },
      "source": [
        "Features =  1#@param {type:\"integer\"}\n",
        "Timesteps =  1792#@param {type:\"integer\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGc1YZ0bnDk4"
      },
      "source": [
        "####**Aufgabe 3.7:** Definieren ein LSTM-Network mit den folgenden Parametern:\n",
        "\n",
        "\n",
        "1.   1 LSTM Hidden Layer mit 8 Units mit dem Fashion-Mnist Input-Shape\n",
        "2.   1 Dense Hidden Layer mit 32 Units\n",
        "3.   1 Dense Output Layer mit der Anzahl der Units, die zu Fashion-Mnist    Dataset passt\n",
        "4. Verwenden Sie auch passende Aktivierungs-Funktionen pro Layer\n",
        "\n",
        "Erstellen Sie dazu die Funktion\n",
        "\n",
        "```\n",
        "def build_lstm_model()\n",
        "```\n",
        "die eine Model-Instanz (Objekt) zurück gibt.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYJqUeuo2Q7K"
      },
      "source": [
        "from tensorflow import keras\n",
        "def build_lstm_model():\n",
        "  # Aufgabe 3.7\n",
        "  model = keras.Sequential([ \n",
        "    keras.layers.LSTM(8),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrSfHI316bO8"
      },
      "source": [
        "####**Aufgabe 3.8:** Erstellen Sie nun eine Model-Instanz mit Hilfe der eben definierten Funktion \n",
        "```\n",
        "def build_lstm_model()\n",
        "```\n",
        "####Ergänzen Sie das fehlende Loss. Bitte, folgendes dabei beachten: Die Labels sind **nicht** one-hot encoded, sondern Integers von 0 bis 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6cGiqyy6pZ9"
      },
      "source": [
        "model = build_lstm_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # Fashion-Mnist labels sind Integers\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehgQl5MqpJlJ"
      },
      "source": [
        "####**Aufgabe 3.9:** Fitten Sie das Model auf Trainings-Daten für **5 Epochen**. Das Model soll ca. 81% Accuracy erreichen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S48-uvT8XEav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960e4313-971f-4c42-cdba-06ea55ccb466"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.7180 - accuracy: 0.7348\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.6141 - accuracy: 0.7758\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.5643 - accuracy: 0.7956\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.5264 - accuracy: 0.8089\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4999 - accuracy: 0.8222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f95352e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1wxVJ3E93fU"
      },
      "source": [
        "####**Aufgabe 3.10:** Konvertieren Sie die Labels zu **one-hot-encoded** mit Hilfe von einer passenden Funktion aus ***tf.keras.utils*** Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMCCIJs0VlhQ"
      },
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozAUkoq4qywd"
      },
      "source": [
        "####**Aufgabe 3.11:** Erstellen Sie wieder eine neue Model-Instanz mit ``` build_lstm_model()``` und ergänzen Sie das fehlende Loss. Die Labels sind nun one-hot-encoded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv-ehh9j-TDL"
      },
      "source": [
        "model = build_lstm_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy', # labels sind nun one-hot encoded\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4E94gaurNwJ"
      },
      "source": [
        "####**Aufgabe 3.12:** Fitten Sie wieder das Model auf den Train Daten für 5 Epochen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-qt9oiaOtl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12b89b0-dc5c-4823-a4c9-79b91066a5cb"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 17s 8ms/step - loss: 0.3064 - accuracy: 0.3108\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1489 - accuracy: 0.6743\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1267 - accuracy: 0.7212\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1121 - accuracy: 0.7487\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1039 - accuracy: 0.7744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f935bc110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI3iguP7DJAb"
      },
      "source": [
        "## **CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R3kbE0XDy3K"
      },
      "source": [
        "### Aufgabe 4:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWhugvB4vFYJ"
      },
      "source": [
        "Wir laden wieder das Fashion-Mnist Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reQAC_98biOR"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIF_HuxxbiOS"
      },
      "source": [
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7IATHMaEAGJ"
      },
      "source": [
        "####**Aufgabe 4.1:** Definieren ein CNN-Network mit den folgenden Parametern:\n",
        "\n",
        "\n",
        "1.   1 Flatten Layer\n",
        "2.   1 MaxPooling2D Hidden Layer mit Pooling Size von 2\n",
        "3.   1 Dense Hidden Layer mit 32 Units\n",
        "4.   1 Con2D Hidden Layer mit **8 Filters**, **(3, 3) Kernel-Size** mit dem Fashion-Mnist Input-Shape. **Input-Shape** muss **3 Dimensionen** haben. Beachten Sie bitte, dass die Fashion-Mnist Images Schwarz-Weiss sind.\n",
        "5.   1 Dense Output Layer mit der Anzahl der Units, die zu Fashion-Mnist    Dataset passt\n",
        "6.   Verwenden Sie auch passende Aktivierungs-Funktionen pro Layer, wenn nötig\n",
        "7.   Printen Sie das Model-Summary\n",
        "8.   **Sie müssen die o.a. Layers in der richtigen Reihenfolge einfügen!**\n",
        "\n",
        "Erstellen Sie dazu die Funktion\n",
        "\n",
        "```\n",
        "def build_cnn_model()\n",
        "```\n",
        "die eine Model-Instanz (Objekt) zurück gibt und summary printet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-pLJ3nBExor"
      },
      "source": [
        "from keras import models, layers\n",
        "def build_cnn_model():\n",
        "  model = models.Sequential()\n",
        " \n",
        "  #Aufgabe 4.1 \n",
        "  model.add(layers.Conv2D(8, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(32,activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPhwoVGu3dMq"
      },
      "source": [
        "####**Aufgabe 4.2:** Erstellen Sie und kompillieren Sie mit ```model.compile``` das CNN Model. Verwenden Sie 'adam' Optimizer und die Metric 'accuracy'. Wählen Sie das passende Loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APZejtDSXXlv"
      },
      "source": [
        "model = build_cnn_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # labels sind nun one-hot encoded\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzO5U0Gq5SzO"
      },
      "source": [
        "####**Aufgabe 4.3:** Bevor Sie das model fitten können, müssen Sie die Inputdaten in 4 Dimensionen reshapen. Die letzte Dimension fehlt noch. Bitte ergänzen Sie diese."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVFoOyQKa8KD",
        "outputId": "67b9dfa5-f8f4-41e3-ecbb-37a65952b275"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqlMO1-_Y9Th"
      },
      "source": [
        "# Aufgabe 4.3 code hier\n",
        "train_images = np.expand_dims(train_images, axis=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq5Ny_g6bO9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e4cce4-d714-4e76-c8d9-ebdddb573f3a"
      },
      "source": [
        "# Shape (60000, 28, 28, 1) ist erforderlich\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIXLXGp8buTA",
        "outputId": "5b9045c4-17f1-4331-8709-2a84f708b30d"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6jc0Obj8dlj"
      },
      "source": [
        "####**Aufgabe 4.4:** Fitten Sie das Model für 5 Epochen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHnVCfCgXdCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70ae5ab-d4b9-4a23-9553-e9c3272b4705"
      },
      "source": [
        "model.fit(train_images,train_labels,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.6382 - accuracy: 0.7796\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3489 - accuracy: 0.8773\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2999 - accuracy: 0.8929\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2773 - accuracy: 0.9003\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2535 - accuracy: 0.9086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f86433610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07z85Jod9zcd"
      },
      "source": [
        "####**Aufgabe 4.5:**  Gegeben ist nun ein Dataset mit 60.000 **Farb-Images** der Grösse 120 x 60 Pixel (Höhe x Breite). Sie wollen ein CNN-Model mit batch_size=32 darauf trainieren. Bitte, **ein** korrektes **Input-Shape** für das CNN-Input auswählen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2z5u8l00mhC",
        "cellView": "form"
      },
      "source": [
        "input_dimension_cnn = '(None, 120, 60, 3)' #@param [\"please select\", \"(None, 120, 60)\", \"(None, 120, 60, 3)\", \"(None, 32, 120, 60, 3)\", \"(None, 60, 120, 3)\", \"(None, 120, 60, 1)\"] {allow-input: false}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFmP580Y3QSH"
      },
      "source": [
        "####**Aufgabe 4.6:** Beschreiben Sie bitte kurz die Bedeutung jeder Dimension des von Ihnen ausgewählten Shapes.\n",
        "\n",
        "#### Beispiel: (None, 120). \n",
        "#### Für was steht **None**?\n",
        "#### Für was steht **120**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIfn-WEx3vFm",
        "cellView": "form"
      },
      "source": [
        "dim_1 = \"Batch size\" #@param {type:\"string\"}\n",
        "dim_2 = \"Image height\" #@param {type:\"string\"}\n",
        "dim_3 = \"Image width\" #@param {type:\"string\"}\n",
        "dim_4 = \"Color channels\" #@param {type:\"string\"}\n",
        "dim_5 = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJzuBkKO3k05"
      },
      "source": [
        "#**Reinforcement Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzybwCuB0HwB"
      },
      "source": [
        "## Allgemeine Fragen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD_xvKJpPAh2"
      },
      "source": [
        "### Aufgabe 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IF4GV-DPETo"
      },
      "source": [
        "####**Aufgabe 5.1:** Definieren Sie mit eigenen Worten die **Markov Property**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zoghNKsDP0qA"
      },
      "source": [
        "Antwort = \"Markov property is the probability of the next state, given the current state and current action, will be the same as if you give the entire history of interactions (states and actions)\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1EDYKYFQBmS"
      },
      "source": [
        "####**Aufgabe 5.2:** Definieren Sie mit eigenen Worten die **State-Action-Value Function** $Q(s,a)$. Was berechnet diese Funktion?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vQ8vI_D6RTFX"
      },
      "source": [
        "Antwort = \"It defines how good it is for an agent to do an action in a given state\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF86gDGaQcMv"
      },
      "source": [
        "####**Aufgabe 5.3:** Deep Reinforcement Learning ist dem traditionnelen Supervised-Learning (Machine Learning oder Deep Learning) immer überlegen. Stimmt diese Aussage?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Z4-mQJvZRRBf"
      },
      "source": [
        "Antwort = \"nein\" #@param [\"please select\", \"ja\", \"nein\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQtD2_eESbGC"
      },
      "source": [
        "####**Aufgabe 5.4:** Model eines Environments wird durch dessen Transition- und Reward-Function definiert. Stimm diese Aussage?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "asy0pw1PTMAE"
      },
      "source": [
        "Antwort = \"ja\" #@param [\"please select\", \"ja\", \"nein\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu6FP030TqTt"
      },
      "source": [
        "####**Aufgabe 5.5:** Gegeben sind State-Value Function $V(s)$ und die State-Action-Value Function $Q(s,a)$. Definieren Sie die Advantage Function $A(s,a)$ mit Hilfe von $V(s)$ und $Q(s,a)$. Benutzen Sie vereinfacht Symbole A, V und Q."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9XqVb4mvUt_M"
      },
      "source": [
        "Antwort = \"A = Q - V\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSKNfhPZ0NgB"
      },
      "source": [
        "## **DQN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzf1q7kuCu9o"
      },
      "source": [
        "###Aufgabe 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dIvskOMC-6B"
      },
      "source": [
        "Gegeben sind:\n",
        "\n",
        "\n",
        "1.   Cart-Pole Environment v1 (CartPole-v1).\n",
        "2.   GreedyStrategy Klasse, um die Aktionen während \"Play\" aufzurufen.\n",
        "3.   EGreedyExpStrategy Klasse, um die Aktionen während \"Train\" aufzurufen. Diese Klasse sorgt auch für einen sanften exponetiellen Abstieg von epsilon.\n",
        "4.   Die Methode der Agenten-Klasse **get_action** wurde entfernt. Stattdessen soll die Methode der beiden o.a. Klassen ```select_action(model, state)``` verwendet werden.\n",
        "5.  Zusätzlich zu der bekannten Methode der DQN Klasse ```update_model(other_model: Model)``` (diese kopiert sämtliche Gewichte von Online zu Target Model) gibt es die neue Methode ```update_model_mixed(other_model: Model, tau=None).``` Diese neue Methode kombiniert die Gewichte von Online und Target Model, vobei tau-Prozentanteil von Online-Model in Target-Model hineinfliesst.\n",
        "6. **Der o.a. Code ist vollständig und lauffähig. Sie müssen nichts neu kodieren!**\n",
        "7.  Die Aufgaben werden es sein, diesen Code **zu verwenden**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhs9kvp2DLAw"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHJuB9kkVwpI"
      },
      "source": [
        "import random\n",
        "import collections\n",
        "import os\n",
        "import numpy as np\n",
        "from itertools import cycle, count\n",
        "\n",
        "import gym\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6no5PwixfNW2"
      },
      "source": [
        "**Pfade und Model-Verzeichnis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhakcWtsW50o"
      },
      "source": [
        "MODELS_PATH = \"content/models\"\n",
        "MODEL_PATH = os.path.join(MODELS_PATH, \"dqn.h5\")\n",
        "TARGET_MODEL_PATH = os.path.join(MODELS_PATH, \"target_dqn.h5\")\n",
        "\n",
        "if not os.path.exists(MODELS_PATH):\n",
        "    os.makedirs(MODELS_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdN6pYPIfU7m"
      },
      "source": [
        "**Environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Fh-ZlTjgI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8104381b-9490-4af4-d4ee-6f7996c561e0"
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "print(\"Observation Space:\", env.observation_space.shape)\n",
        "print(\"Action Space:\", env.action_space.n)\n",
        "print(\"Max. Steps per Episode:\", env.spec.max_episode_steps)\n",
        "print(\"Reward Threshold:\", env.spec.reward_threshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Space: (4,)\n",
            "Action Space: 2\n",
            "Max. Steps per Episode: 500\n",
            "Reward Threshold: 475.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTo4IajhfbjF"
      },
      "source": [
        "**Greedy Strategy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td9Y5dgzouPg"
      },
      "source": [
        "class GreedyStrategy():\n",
        "    def __init__(self):\n",
        "        self.exploratory_action_taken = False\n",
        "\n",
        "    def select_action(self, model, state):\n",
        "      q_values = model(state)\n",
        "      return np.argmax(q_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDLZp5GbfhpQ"
      },
      "source": [
        "**Epsilon Greedy Strategy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnHOqnsErh6W"
      },
      "source": [
        "class EGreedyExpStrategy():\n",
        "    def __init__(self, init_epsilon=1.0, min_epsilon=0.01, decay_steps=20000):\n",
        "        self.epsilon = init_epsilon\n",
        "        self.init_epsilon = init_epsilon\n",
        "        self.decay_steps = decay_steps\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.epsilons = 0.01 / np.logspace(-2, 0, decay_steps, endpoint=False) - 0.01\n",
        "        self.epsilons = self.epsilons * (init_epsilon - min_epsilon) + min_epsilon\n",
        "        self.t = 0\n",
        "        self.exploratory_action_taken = None\n",
        "\n",
        "    def _epsilon_update(self):\n",
        "        self.epsilon = self.min_epsilon if self.t >= self.decay_steps else self.epsilons[self.t]\n",
        "        self.t += 1\n",
        "        return self.epsilon\n",
        "\n",
        "    def select_action(self, model, state):\n",
        "        self.exploratory_action_taken = False\n",
        "       \n",
        "        q_values = model(state)\n",
        "\n",
        "        if np.random.rand() > self.epsilon:\n",
        "            action = np.argmax(q_values)\n",
        "        else:\n",
        "            action = np.random.randint(len(q_values))\n",
        "\n",
        "        self._epsilon_update()\n",
        "        self.exploratory_action_taken = action != np.argmax(q_values)\n",
        "        return action\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIg5suk1j6cU"
      },
      "source": [
        "####**Aufgabe 6.1:** Innerhalb der **```train```** Methode der Agenten-Klasse rufen Sie die Methode  ```self.strategy.select_action(model, state)``` der **```EGreedyExpStrategy```** Klasse auf. Diese Methode gibt die Aktion zurück und selektiert ab und zu random actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fZgBYaul-C-"
      },
      "source": [
        "####**Aufgabe 6.2:** Innerhalb der **```train```** Methode der Agenten Klasse rufen Sie die Methode ```update_model(other_model: Model)``` auf. Diese Methode soll nur unter folgender Bedingung aufgerufen werden: ```current_reward_mean > best_reward_mean.``` Sie überträgt sämtliche Gewichte des Online Models auf das Target Model, nur wenn das Online Model Fortschritte macht."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLV9xPVLnP7T"
      },
      "source": [
        "####**Aufgabe 6.3:** Innerhalb der **```train```** Methode der Agenten Klasse rufen Sie die Methode ```update_model_mixed(other_model: Model, tau=0.1)``` auf. Diese Methode soll nur alle **100 Steps** aufgerufen werden. Verwenden Sie dazu diese Bedingung ```if step%self.num_update_steps == 0``` mit ```self.num_update_steps=100.```Der Parameter **```tau = 0.1```**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDU7-XuSr2ws"
      },
      "source": [
        "####**Aufgabe 6.4:** Innerhalb der **```play```** Methode der Agenten-Klasse rufen Sie die Methode  ```self.strategy.select_action(model, state)``` der **```GreedyStrategy```** Klasse auf. Diese Methode gibt die Aktion zurück, ohne zufällige Aktionen auszuwählen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzmFxyOAfm-o"
      },
      "source": [
        "**Agent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTn2tpR1Vj4T"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, env: gym.Env, strategy):\n",
        "        # DQN Env Variables\n",
        "        self.env = env\n",
        "        self.observations = self.env.observation_space.shape\n",
        "        self.actions = self.env.action_space.n\n",
        "        # DQN Agent Variables\n",
        "        self.replay_buffer_size = 50_000\n",
        "        self.train_start = 500\n",
        "        self.memory: Deque = collections.deque(\n",
        "            maxlen=self.replay_buffer_size\n",
        "        )\n",
        "        self.gamma = .996\n",
        "        self.tau = .1\n",
        "       \n",
        "        self.state_shape = self.observations\n",
        "        self.learning_rate = 5e-4\n",
        "        self.dqn = DQN(\n",
        "            self.state_shape,\n",
        "            self.actions,\n",
        "            self.learning_rate,\n",
        "            self.tau\n",
        "\n",
        "        )\n",
        "        self.target_dqn = DQN(\n",
        "            self.state_shape,\n",
        "            self.actions,\n",
        "            self.learning_rate,\n",
        "            self.tau\n",
        "        )\n",
        "        self.batch_size = 32\n",
        "        self.num_update_steps = 100\n",
        "        \n",
        "        self.strategy = strategy\n",
        "\n",
        "\n",
        "    def train(self, num_episodes: int):\n",
        "        last_rewards: Deque = collections.deque(maxlen=5)\n",
        "        best_reward_mean = 0.0\n",
        "\n",
        "        for episode in range(1, num_episodes + 1):\n",
        "            total_reward = 0.0\n",
        "            state = self.env.reset()\n",
        "            state = np.reshape(state, newshape=(1, -1)).astype(np.float32)\n",
        "\n",
        "            for step in count():\n",
        "                # 6.1:\n",
        "                action = self.strategy.select_action(self.dqn,state) \n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = np.reshape(next_state, newshape=(1, -1)).astype(np.float32)\n",
        "                \n",
        "                if done and total_reward < env.spec.reward_threshold:\n",
        "                  reward = -100.0\n",
        "\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                self.replay()\n",
        "                total_reward += reward\n",
        "                state = next_state\n",
        "                \n",
        "                # 6.3:\n",
        "                if step%self.num_update_steps == 0:\n",
        "                  self.target_dqn.update_model_mixed(self.dqn, self.tau)\n",
        "\n",
        "                if done:\n",
        "                  if total_reward < env.spec.reward_threshold:\n",
        "                    total_reward += 100.0\n",
        "                  print(f\"Episode: {episode} Reward: {total_reward} Epsilon: {self.strategy.epsilon}\")\n",
        "                  last_rewards.append(total_reward)\n",
        "                  current_reward_mean = np.mean(last_rewards)\n",
        "\n",
        "                  if current_reward_mean > best_reward_mean:\n",
        "                      # 6.2:\n",
        "                      self.target_dqn.update_model(self.dqn)\n",
        "                      best_reward_mean = current_reward_mean\n",
        "                      self.dqn.save_model(MODEL_PATH)\n",
        "                      self.target_dqn.save_model(TARGET_MODEL_PATH)\n",
        "                      print(f\"New best mean: {best_reward_mean}\")\n",
        "                      if best_reward_mean > 470:\n",
        "                        print(\"Environment solved! Stop training...\")\n",
        "                        return   \n",
        "                  break\n",
        "\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self):\n",
        "        if len(self.memory) < self.train_start:\n",
        "            return\n",
        "        minibatch = random.sample(self.memory, self.batch_size)\n",
        "        states, actions, rewards, states_next, dones = zip(*minibatch)\n",
        "\n",
        "        states = np.concatenate(states).astype(np.float32)\n",
        "        states_next = np.concatenate(states_next).astype(np.float32)\n",
        "       \n",
        "        rewards = np.array(rewards).astype(np.float32)\n",
        "        dones = np.array(dones)\n",
        "\n",
        "        q_values = self.dqn(states)\n",
        "        q_values_next = self.target_dqn(states_next)\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            a = actions[i]\n",
        "            done = dones[i]\n",
        "            if done:\n",
        "                q_values[i][a] = rewards[i]\n",
        "            else:\n",
        "                q_values[i][a] = rewards[i] + self.gamma * np.max(q_values_next[i])\n",
        "\n",
        "        self.dqn.fit(states, q_values)\n",
        "\n",
        "\n",
        "    def play(self, num_episodes: int):\n",
        "        self.dqn.load_model(MODEL_PATH)\n",
        "        self.target_dqn.load_model(TARGET_MODEL_PATH)\n",
        "\n",
        "        for episode in range(1, num_episodes + 1):\n",
        "            total_reward = 0.0\n",
        "            state = self.env.reset()\n",
        "            state = np.reshape(state, newshape=(1, -1)).astype(np.float32)\n",
        "\n",
        "            while True:\n",
        "                # 6.4:\n",
        "                action = self.strategy.select_action(self.dqn,state) \n",
        "                next_state, reward, done, info = self.env.step(action)\n",
        "                next_state = np.reshape(next_state, newshape=(1, -1)).astype(np.float32)\n",
        "                total_reward += reward\n",
        "                state = next_state\n",
        "\n",
        "                if done:\n",
        "                    print(f\"Episode: {episode} Reward: {total_reward}\")\n",
        "                    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TviQjsCpfrQj"
      },
      "source": [
        "**DQN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2pGzSI4DM-d"
      },
      "source": [
        "\n",
        "class DQN(Model):\n",
        "    def __init__(self, state_shape: int, num_actions: int, learning_rate: float, tau: float):\n",
        "        super().__init__()\n",
        "        self.state_shape = state_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.learning_rate = learning_rate\n",
        "        self.tau = tau\n",
        "        self.internal_model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        input_state = Input(shape=self.state_shape)\n",
        "        x = Dense(units=32)(input_state)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Dense(units=32)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        q_value_pred = Dense(self.num_actions)(x)\n",
        "        model = Model(\n",
        "            inputs=input_state,\n",
        "            outputs=q_value_pred\n",
        "        )\n",
        "        model.compile(\n",
        "            loss=\"mse\",\n",
        "            optimizer=Adam(learning_rate=self.learning_rate)\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def call(self, inputs: np.ndarray) -> np.ndarray:\n",
        "        return self.internal_model(inputs).numpy()\n",
        "\n",
        "    def fit(self, states: np.ndarray, q_values: np.ndarray):\n",
        "        self.internal_model.fit(x=states, y=q_values, verbose=0)\n",
        "\n",
        "    def update_model(self, other_model: Model):\n",
        "        self.internal_model.set_weights(other_model.get_weights())\n",
        "\n",
        "    def update_model_mixed(self, other_model: Model, tau=None):\n",
        "        new_target_weights = []\n",
        "        tau = self.tau if tau is None else tau\n",
        "        for target, online in zip(self.internal_model.get_weights(), other_model.get_weights()):\n",
        "          target_ratio = (1.0 - self.tau) * target #target_model\n",
        "          online_ratio = self.tau * online # online_model\n",
        "          mixed_weights = target_ratio + online_ratio\n",
        "          new_target_weights.append(mixed_weights)\n",
        "\n",
        "        self.internal_model.set_weights(new_target_weights)\n",
        "\n",
        "    def load_model(self, path: str):\n",
        "        self.internal_model.load_weights(path)\n",
        "\n",
        "    def save_model(self, path: str):\n",
        "        self.internal_model.save_weights(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wooyIlvIsl5v"
      },
      "source": [
        "####**Aufgabe 6.5:** Übergeben Sie ein ```EGreedyExpStrategy``` Objekt an den ```strategy``` Parameter des Agent-Konstruktors mit den Parameter Werten: **```init_epsilon=0.02, min_epsilon=0.01.```** Trainieren Sie den Agenten für **200 Episoden**. Falls Ihre vorherige Implementierung korrekt ist, wird er das Cart-Pole Environment in **ca. 200 Episoden lösen**! \n",
        "\n",
        "---\n",
        "\n",
        "Beachten Sie, dass der Anfangs-Epsilon Wert mit nur 0.02 gesetzt wurde.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDH2pFlJfuue"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkIbjofvmda5"
      },
      "source": [
        "# Comment Cédric Moullet: this part takes more than 20 minutes. I stopped it after 159 episodes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwwM2oA1JIrm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "574f9c90-6a8a-4932-86d5-5d86fe24ce2a"
      },
      "source": [
        "agent = Agent(env, strategy=EGreedyExpStrategy(init_epsilon=0.02, min_epsilon=0.01))\n",
        "agent.train(num_episodes=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 1 Reward: 9.0 Epsilon: 0.019879298192025278\n",
            "New best mean: 9.0\n",
            "Episode: 2 Reward: 17.0 Epsilon: 0.019838023056811184\n",
            "New best mean: 13.0\n",
            "Episode: 3 Reward: 11.0 Epsilon: 0.01981060118647831\n",
            "Episode: 4 Reward: 16.0 Epsilon: 0.01977188301068396\n",
            "New best mean: 13.25\n",
            "Episode: 5 Reward: 13.0 Epsilon: 0.01974011105761134\n",
            "Episode: 6 Reward: 22.0 Epsilon: 0.019688136113351812\n",
            "New best mean: 15.8\n",
            "Episode: 7 Reward: 13.0 Epsilon: 0.019656633693709555\n",
            "Episode: 8 Reward: 16.0 Epsilon: 0.01961851702940169\n",
            "New best mean: 16.0\n",
            "Episode: 9 Reward: 28.0 Epsilon: 0.0195538378511649\n",
            "New best mean: 18.4\n",
            "Episode: 10 Reward: 24.0 Epsilon: 0.01949842553582907\n",
            "New best mean: 20.6\n",
            "Episode: 11 Reward: 17.0 Epsilon: 0.019458725718846912\n",
            "Episode: 12 Reward: 14.0 Epsilon: 0.019425767998554604\n",
            "Episode: 13 Reward: 32.0 Epsilon: 0.019353660459579654\n",
            "New best mean: 23.0\n",
            "Episode: 14 Reward: 20.0 Epsilon: 0.019308058300365895\n",
            "Episode: 15 Reward: 23.0 Epsilon: 0.019256210840627026\n",
            "Episode: 16 Reward: 21.0 Epsilon: 0.019208935046377294\n",
            "Episode: 17 Reward: 17.0 Epsilon: 0.019170432584045275\n",
            "Episode: 18 Reward: 9.0 Epsilon: 0.019149111180764646\n",
            "Episode: 19 Reward: 8.0 Epsilon: 0.01912996384840454\n",
            "Episode: 20 Reward: 8.0 Epsilon: 0.019110856154484206\n",
            "Episode: 21 Reward: 16.0 Epsilon: 0.01907487170297663\n",
            "Episode: 22 Reward: 8.0 Epsilon: 0.019055878059757853\n",
            "Episode: 23 Reward: 8.0 Epsilon: 0.019036923736814544\n",
            "Episode: 24 Reward: 23.0 Epsilon: 0.01898657048958146\n",
            "Episode: 25 Reward: 30.0 Epsilon: 0.01892194136035736\n",
            "Episode: 26 Reward: 20.0 Epsilon: 0.01887842170909727\n",
            "Episode: 27 Reward: 8.0 Epsilon: 0.018859834752883484\n",
            "Episode: 28 Reward: 8.0 Epsilon: 0.01884128627502954\n",
            "Episode: 29 Reward: 16.0 Epsilon: 0.018806354963869877\n",
            "Episode: 30 Reward: 39.0 Epsilon: 0.018724701010756545\n",
            "Episode: 31 Reward: 21.0 Epsilon: 0.0186801108709653\n",
            "Episode: 32 Reward: 22.0 Epsilon: 0.018633734791423204\n",
            "Episode: 33 Reward: 20.0 Epsilon: 0.018591605378568563\n",
            "New best mean: 23.6\n",
            "Episode: 34 Reward: 9.0 Epsilon: 0.0185716152409183\n",
            "Episode: 35 Reward: 10.0 Epsilon: 0.018549679187756934\n",
            "Episode: 36 Reward: 17.0 Epsilon: 0.01851390345772428\n",
            "Episode: 37 Reward: 31.0 Epsilon: 0.018450667128846833\n",
            "Episode: 38 Reward: 21.0 Epsilon: 0.018407461648896978\n",
            "Episode: 39 Reward: 36.0 Epsilon: 0.018335289651265293\n",
            "Episode: 40 Reward: 8.0 Epsilon: 0.018317827076608124\n",
            "Episode: 41 Reward: 8.0 Epsilon: 0.01830040065263769\n",
            "Episode: 42 Reward: 8.0 Epsilon: 0.018283010304515526\n",
            "Episode: 43 Reward: 8.0 Epsilon: 0.018265655957558104\n",
            "Episode: 44 Reward: 8.0 Epsilon: 0.0182483375372365\n",
            "Episode: 45 Reward: 9.0 Epsilon: 0.01822913689371308\n",
            "Episode: 46 Reward: 7.0 Epsilon: 0.018213808179156223\n",
            "Episode: 47 Reward: 9.0 Epsilon: 0.01819468695095263\n",
            "Episode: 48 Reward: 9.0 Epsilon: 0.018175609700353534\n",
            "Episode: 49 Reward: 16.0 Epsilon: 0.018143279016759804\n",
            "Episode: 50 Reward: 15.0 Epsilon: 0.018112965528345543\n",
            "Episode: 51 Reward: 34.0 Epsilon: 0.018047042840208395\n",
            "Episode: 52 Reward: 40.0 Epsilon: 0.017970491789118657\n",
            "Episode: 53 Reward: 21.0 Epsilon: 0.017929712576698627\n",
            "New best mean: 25.2\n",
            "Episode: 54 Reward: 20.0 Epsilon: 0.017890979195810987\n",
            "New best mean: 26.0\n",
            "Episode: 55 Reward: 25.0 Epsilon: 0.017843282347242813\n",
            "New best mean: 28.0\n",
            "Episode: 56 Reward: 31.0 Epsilon: 0.017784969177453775\n",
            "Episode: 57 Reward: 73.0 Epsilon: 0.017651754320690806\n",
            "New best mean: 34.0\n",
            "Episode: 58 Reward: 90.0 Epsilon: 0.017491017628812527\n",
            "New best mean: 47.8\n",
            "Episode: 59 Reward: 34.0 Epsilon: 0.017430087105475896\n",
            "New best mean: 50.6\n",
            "Episode: 60 Reward: 43.0 Epsilon: 0.017354182133789905\n",
            "New best mean: 54.2\n",
            "Episode: 61 Reward: 48.0 Epsilon: 0.017270551753379344\n",
            "New best mean: 57.6\n",
            "Episode: 62 Reward: 26.0 Epsilon: 0.0172248713266504\n",
            "Episode: 63 Reward: 61.0 Epsilon: 0.017121044144820456\n",
            "Episode: 64 Reward: 31.0 Epsilon: 0.017068033065160516\n",
            "Episode: 65 Reward: 50.0 Epsilon: 0.016984349849515065\n",
            "Episode: 66 Reward: 29.0 Epsilon: 0.016935581528181837\n",
            "Episode: 67 Reward: 100.0 Epsilon: 0.01677384919590323\n",
            "Episode: 68 Reward: 28.0 Epsilon: 0.01672810199846873\n",
            "Episode: 69 Reward: 54.0 Epsilon: 0.01664217467576244\n",
            "Episode: 70 Reward: 41.0 Epsilon: 0.01657728633464277\n",
            "Episode: 71 Reward: 26.0 Epsilon: 0.016535902555061006\n",
            "Episode: 72 Reward: 26.0 Epsilon: 0.01649477525949485\n",
            "Episode: 73 Reward: 33.0 Epsilon: 0.01644334772373758\n",
            "Episode: 74 Reward: 61.0 Epsilon: 0.01635059833284832\n",
            "Episode: 75 Reward: 29.0 Epsilon: 0.016306192726268983\n",
            "Episode: 76 Reward: 33.0 Epsilon: 0.01625623579937844\n",
            "Episode: 77 Reward: 40.0 Epsilon: 0.01619651148701626\n",
            "Episode: 78 Reward: 35.0 Epsilon: 0.016144533502805022\n",
            "Episode: 79 Reward: 43.0 Epsilon: 0.016081587200579915\n",
            "Episode: 80 Reward: 51.0 Epsilon: 0.01600801366500168\n",
            "Episode: 81 Reward: 45.0 Epsilon: 0.015943659664361794\n",
            "Episode: 82 Reward: 41.0 Epsilon: 0.015885494002869496\n",
            "Episode: 83 Reward: 68.0 Epsilon: 0.015791148903295416\n",
            "Episode: 84 Reward: 28.0 Epsilon: 0.01575194182378082\n",
            "Episode: 85 Reward: 52.0 Epsilon: 0.015680960474057183\n",
            "Episode: 86 Reward: 37.0 Epsilon: 0.015630598740537325\n",
            "Episode: 87 Reward: 44.0 Epsilon: 0.01557152694860832\n",
            "Episode: 88 Reward: 31.0 Epsilon: 0.015529891173942434\n",
            "Episode: 89 Reward: 74.0 Epsilon: 0.015433501092157366\n",
            "Episode: 90 Reward: 68.0 Epsilon: 0.015346280436471701\n",
            "Episode: 91 Reward: 231.0 Epsilon: 0.015062974736975886\n",
            "New best mean: 89.6\n",
            "Episode: 92 Reward: 88.0 Epsilon: 0.01495824662003114\n",
            "New best mean: 98.4\n",
            "Episode: 93 Reward: 36.0 Epsilon: 0.014915335611066591\n",
            "New best mean: 99.4\n",
            "Episode: 94 Reward: 62.0 Epsilon: 0.014843106869868354\n",
            "Episode: 95 Reward: 169.0 Epsilon: 0.014653352259428053\n",
            "New best mean: 117.2\n",
            "Episode: 96 Reward: 45.0 Epsilon: 0.01460327096440778\n",
            "Episode: 97 Reward: 38.0 Epsilon: 0.01456122428001887\n",
            "Episode: 98 Reward: 76.0 Epsilon: 0.01447930953151744\n",
            "Episode: 99 Reward: 265.0 Epsilon: 0.014207249209819748\n",
            "New best mean: 118.6\n",
            "Episode: 100 Reward: 87.0 Epsilon: 0.014120850791798844\n",
            "Episode: 101 Reward: 48.0 Epsilon: 0.014073495984653172\n",
            "Episode: 102 Reward: 69.0 Epsilon: 0.014006766398748219\n",
            "Episode: 103 Reward: 48.0 Epsilon: 0.013960691533656346\n",
            "Episode: 104 Reward: 57.0 Epsilon: 0.013906821541822111\n",
            "Episode: 105 Reward: 46.0 Epsilon: 0.013863692911508105\n",
            "Episode: 106 Reward: 52.0 Epsilon: 0.013815615148396116\n",
            "Episode: 107 Reward: 92.0 Epsilon: 0.013732657404000346\n",
            "Episode: 108 Reward: 302.0 Epsilon: 0.013474374062644809\n",
            "Episode: 109 Reward: 195.0 Epsilon: 0.013316646128138224\n",
            "New best mean: 137.4\n",
            "Episode: 110 Reward: 242.0 Epsilon: 0.01313072505689288\n",
            "New best mean: 176.6\n",
            "Episode: 111 Reward: 160.0 Epsilon: 0.013013149665447022\n",
            "New best mean: 198.2\n",
            "Episode: 112 Reward: 338.0 Epsilon: 0.012779386737807976\n",
            "New best mean: 247.4\n",
            "Episode: 113 Reward: 131.0 Epsilon: 0.012693186922253972\n",
            "Episode: 114 Reward: 175.0 Epsilon: 0.012582254607608496\n",
            "Episode: 115 Reward: 128.0 Epsilon: 0.012503754298938735\n",
            "Episode: 116 Reward: 405.0 Epsilon: 0.012271373705661656\n",
            "Episode: 117 Reward: 109.0 Epsilon: 0.012212064790175595\n",
            "Episode: 118 Reward: 292.0 Epsilon: 0.012061225086571403\n",
            "Episode: 119 Reward: 500.0 Epsilon: 0.011826193885924948\n",
            "New best mean: 286.8\n",
            "Episode: 120 Reward: 500.0 Epsilon: 0.011616722107858095\n",
            "New best mean: 361.2\n",
            "Episode: 121 Reward: 234.0 Epsilon: 0.011526297521013409\n",
            "Episode: 122 Reward: 216.0 Epsilon: 0.01144703450394792\n",
            "Episode: 123 Reward: 223.0 Epsilon: 0.011369264549362304\n",
            "Episode: 124 Reward: 200.0 Epsilon: 0.011302813704561957\n",
            "Episode: 125 Reward: 152.0 Epsilon: 0.01125425360392331\n",
            "Episode: 126 Reward: 236.0 Epsilon: 0.011182330582656021\n",
            "Episode: 127 Reward: 348.0 Epsilon: 0.011083313992474461\n",
            "Episode: 128 Reward: 288.0 Epsilon: 0.011007133520425521\n",
            "Episode: 129 Reward: 147.0 Epsilon: 0.010970039968734902\n",
            "Episode: 130 Reward: 500.0 Epsilon: 0.010853674125975585\n",
            "Episode: 131 Reward: 236.0 Epsilon: 0.010803025470328007\n",
            "Episode: 132 Reward: 203.0 Epsilon: 0.010761588711066142\n",
            "Episode: 133 Reward: 345.0 Epsilon: 0.010695609572930021\n",
            "Episode: 134 Reward: 231.0 Epsilon: 0.01065422339584757\n",
            "Episode: 135 Reward: 202.0 Epsilon: 0.010619780372802699\n",
            "Episode: 136 Reward: 376.0 Epsilon: 0.010559933234263564\n",
            "Episode: 137 Reward: 291.0 Epsilon: 0.010517021077743846\n",
            "Episode: 138 Reward: 341.0 Epsilon: 0.010470295572572064\n",
            "Episode: 139 Reward: 348.0 Epsilon: 0.010426259562080318\n",
            "Episode: 140 Reward: 415.0 Epsilon: 0.010378189460665908\n",
            "Episode: 141 Reward: 224.0 Epsilon: 0.010354046152604848\n",
            "Episode: 142 Reward: 259.0 Epsilon: 0.010327661347479727\n",
            "Episode: 143 Reward: 372.0 Epsilon: 0.01029246415735346\n",
            "Episode: 144 Reward: 321.0 Epsilon: 0.010264418150788861\n",
            "Episode: 145 Reward: 500.0 Epsilon: 0.010224788018763538\n",
            "Episode: 146 Reward: 325.0 Epsilon: 0.010201300602418611\n",
            "Episode: 147 Reward: 337.0 Epsilon: 0.010178740452032377\n",
            "New best mean: 371.0\n",
            "Episode: 148 Reward: 342.0 Epsilon: 0.010157572800542521\n",
            "Episode: 149 Reward: 248.0 Epsilon: 0.010143220400907382\n",
            "Episode: 150 Reward: 380.0 Epsilon: 0.010122792209218492\n",
            "Episode: 151 Reward: 320.0 Epsilon: 0.01010691882329489\n",
            "Episode: 152 Reward: 312.0 Epsilon: 0.010092530704507769\n",
            "Episode: 153 Reward: 393.0 Epsilon: 0.010075832843743474\n",
            "Episode: 154 Reward: 300.0 Epsilon: 0.010064058977319955\n",
            "Episode: 155 Reward: 277.0 Epsilon: 0.010053886314981995\n",
            "Episode: 156 Reward: 398.0 Epsilon: 0.010040378306870724\n",
            "Episode: 157 Reward: 336.0 Epsilon: 0.010029897262889786\n",
            "Episode: 158 Reward: 460.0 Epsilon: 0.010016815372986133\n",
            "Episode: 159 Reward: 500.0 Epsilon: 0.010004111810762334\n",
            "New best mean: 394.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-e4c89c0cf49f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEGreedyExpStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-94179becf24b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_episodes)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-94179becf24b>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mq_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values_next\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-a8199337397d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, states, q_values)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1086\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[1;32m   1087\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 2972\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxRd_lwnzcY-"
      },
      "source": [
        "####**Aufgabe 6.6:** Übergeben Sie ein ```GreedyStrategy``` Objekt (ohne Parameter) an den ```strategy``` Parameter des Agent-Konstruktors und spielen Sie **20 Episoden**. Der Reward der zumindest einigen Episoden soll 500 betragen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siVg0LFkfyKX"
      },
      "source": [
        "**Play**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oImhhRCoKDl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5488d429-30c1-479f-8aa1-3b8fba0f2be4"
      },
      "source": [
        "agent = Agent(env, strategy=GreedyStrategy())\n",
        "agent.play(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 1 Reward: 260.0\n",
            "Episode: 2 Reward: 500.0\n",
            "Episode: 3 Reward: 262.0\n",
            "Episode: 4 Reward: 394.0\n",
            "Episode: 5 Reward: 425.0\n",
            "Episode: 6 Reward: 342.0\n",
            "Episode: 7 Reward: 438.0\n",
            "Episode: 8 Reward: 500.0\n",
            "Episode: 9 Reward: 441.0\n",
            "Episode: 10 Reward: 301.0\n",
            "Episode: 11 Reward: 469.0\n",
            "Episode: 12 Reward: 426.0\n",
            "Episode: 13 Reward: 375.0\n",
            "Episode: 14 Reward: 347.0\n",
            "Episode: 15 Reward: 291.0\n",
            "Episode: 16 Reward: 500.0\n",
            "Episode: 17 Reward: 260.0\n",
            "Episode: 18 Reward: 500.0\n",
            "Episode: 19 Reward: 327.0\n",
            "Episode: 20 Reward: 337.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XYHv6RknKUH"
      },
      "source": [
        "# Comment Cédric Moullet: episode 2,8,16 and 18 reaches a 500 !!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZzb24cWJtP3"
      },
      "source": [
        "# **Viel Spass und Erfolg!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWR_dJZqofMs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}